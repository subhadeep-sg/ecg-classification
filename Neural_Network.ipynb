{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ecg_utility\n",
    "from ecg_utility import utils, neural, snapshot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from scipy.io import loadmat\n",
    "from sklearn.metrics import classification_report, plot_confusion_matrix, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_files = sorted(glob.glob('CPSC_extra/*.mat'))\n",
    "hea_files = sorted(glob.glob('CPSC_extra/*.hea'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3453"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mat_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dx</th>\n",
       "      <th>SNOMED CT Code</th>\n",
       "      <th>Abbreviation</th>\n",
       "      <th>CPSC</th>\n",
       "      <th>CPSC-Extra</th>\n",
       "      <th>StPetersburg</th>\n",
       "      <th>PTB</th>\n",
       "      <th>PTB-XL</th>\n",
       "      <th>Georgia</th>\n",
       "      <th>Total</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1st degree av block</td>\n",
       "      <td>270492004</td>\n",
       "      <td>IAVB</td>\n",
       "      <td>722</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>797</td>\n",
       "      <td>769</td>\n",
       "      <td>2394</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>atrial fibrillation</td>\n",
       "      <td>164889003</td>\n",
       "      <td>AF</td>\n",
       "      <td>1221</td>\n",
       "      <td>153</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>1514</td>\n",
       "      <td>570</td>\n",
       "      <td>3475</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>atrial flutter</td>\n",
       "      <td>164890007</td>\n",
       "      <td>AFL</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>73</td>\n",
       "      <td>186</td>\n",
       "      <td>314</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bradycardia</td>\n",
       "      <td>426627000</td>\n",
       "      <td>Brady</td>\n",
       "      <td>0</td>\n",
       "      <td>271</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>288</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>complete right bundle branch block</td>\n",
       "      <td>713427006</td>\n",
       "      <td>CRBBB</td>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>542</td>\n",
       "      <td>28</td>\n",
       "      <td>683</td>\n",
       "      <td>We score 713427006 and 59118001 as the same di...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Dx  SNOMED CT Code Abbreviation  CPSC  \\\n",
       "0                 1st degree av block       270492004         IAVB   722   \n",
       "1                 atrial fibrillation       164889003           AF  1221   \n",
       "2                      atrial flutter       164890007          AFL     0   \n",
       "3                         bradycardia       426627000        Brady     0   \n",
       "4  complete right bundle branch block       713427006        CRBBB     0   \n",
       "\n",
       "   CPSC-Extra  StPetersburg  PTB  PTB-XL  Georgia  Total  \\\n",
       "0         106             0    0     797      769   2394   \n",
       "1         153             2   15    1514      570   3475   \n",
       "2          54             0    1      73      186    314   \n",
       "3         271            11    0       0        6    288   \n",
       "4         113             0    0     542       28    683   \n",
       "\n",
       "                                               Notes  \n",
       "0                                                NaN  \n",
       "1                                                NaN  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4  We score 713427006 and 59118001 as the same di...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mappings_scored = pd.read_csv('CPSC_extra/SNOMED_mappings_scored.csv',sep=';')\n",
    "mappings_scored.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0, ..., -13,  -8, -10],\n",
       "       [ 10,  12,  11, ...,  -1,   4,   7],\n",
       "       [ 10,  13,  12, ...,  12,  12,  18],\n",
       "       ...,\n",
       "       [ 75, 103,  89, ..., 107, 104, 121],\n",
       "       [ 16,  18,  13, ...,   2,   6,   8],\n",
       "       [  9,   9,   4, ...,   3,   2,   3]], dtype=int16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sig = loadmat(mat_files[0])['val']\n",
    "sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>ecg_signal</th>\n",
       "      <th>Lead I</th>\n",
       "      <th>Lead II</th>\n",
       "      <th>Lead III</th>\n",
       "      <th>aVR</th>\n",
       "      <th>aVL</th>\n",
       "      <th>aVF</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [filename, age, gender, diagnosis, ecg_signal, Lead I, Lead II, Lead III, aVR, aVL, aVF, V1, V2, V3, V4, V5, V6]\n",
       "Index: []"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = utils.get_df()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mat, hea in zip(mat_files, hea_files):\n",
    "    read = utils.Read(hea, mat)\n",
    "    df = read.insert_info(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>ecg_signal</th>\n",
       "      <th>Lead I</th>\n",
       "      <th>Lead II</th>\n",
       "      <th>Lead III</th>\n",
       "      <th>aVR</th>\n",
       "      <th>aVL</th>\n",
       "      <th>aVF</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CPSC_extra\\Q0001.mat</td>\n",
       "      <td>53</td>\n",
       "      <td>M</td>\n",
       "      <td>[164867002, 427084000]</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -5.93620328721...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -5.936203287212...</td>\n",
       "      <td>[0.0005936203287212333, 0.006037652244061175, ...</td>\n",
       "      <td>[0.0005936203287212333, 0.006097014276933299, ...</td>\n",
       "      <td>[-0.00029681016436061664, -0.00307818815490271...</td>\n",
       "      <td>[-0.00029681016436061664, -0.00307818815490271...</td>\n",
       "      <td>[0.0006529823615933566, 0.006629545061892868, ...</td>\n",
       "      <td>[0.003086825709350413, 0.03202502921756262, 0....</td>\n",
       "      <td>[0.0026119294463734263, 0.027052438543420584, ...</td>\n",
       "      <td>[0.0010091545588260965, 0.010240264001755145, ...</td>\n",
       "      <td>[0.004452152465409249, 0.04605409825779641, 0....</td>\n",
       "      <td>[0.0009497925259539732, 0.009589009151051332, ...</td>\n",
       "      <td>[0.00053425829584911, 0.005327035360485236, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CPSC_extra\\Q0002.mat</td>\n",
       "      <td>70</td>\n",
       "      <td>F</td>\n",
       "      <td>[164861001]</td>\n",
       "      <td>[[0.0011278786245703433, 0.011542773703162784,...</td>\n",
       "      <td>[0.0011278786245703433, 0.011542773703162784, ...</td>\n",
       "      <td>[0.027603345285537352, 0.27422100573291114, 1....</td>\n",
       "      <td>[0.026475466660967006, 0.26267823202974827, 1....</td>\n",
       "      <td>[-0.014306249922181722, -0.14228999690020525, ...</td>\n",
       "      <td>[-0.012644113001762268, -0.12524210173794084, ...</td>\n",
       "      <td>[0.02700972495681611, 0.26818335348884986, 1.3...</td>\n",
       "      <td>[0.0026712914792455496, 0.02693198696678679, 0...</td>\n",
       "      <td>[0.0007717064273376033, 0.00811014086191687, 0...</td>\n",
       "      <td>[0.0013653267560588367, 0.013850982941617431, ...</td>\n",
       "      <td>[0.0035023599394552766, 0.03539657251504687, 0...</td>\n",
       "      <td>[-0.019767556946417065, -0.1963879639434882, -...</td>\n",
       "      <td>[-0.009023028996562746, -0.08854301952148638, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CPSC_extra\\Q0003.mat</td>\n",
       "      <td>55</td>\n",
       "      <td>M</td>\n",
       "      <td>[164867002, 428750005]</td>\n",
       "      <td>[[-0.0027900155449897966, -0.02781896243808956...</td>\n",
       "      <td>[-0.0027900155449897966, -0.027818962438089567...</td>\n",
       "      <td>[0.00035617219723273994, 0.003551356906990157,...</td>\n",
       "      <td>[0.0031461877422225364, 0.03137031934507972, 0...</td>\n",
       "      <td>[0.0012466026903145896, 0.012429749174465547, ...</td>\n",
       "      <td>[-0.002968101643606166, -0.029594640891584638,...</td>\n",
       "      <td>[0.0017808609861636997, 0.01775678453495079, 0...</td>\n",
       "      <td>[-0.0008310684602097266, -0.008405223515387946...</td>\n",
       "      <td>[-0.0018995850519079463, -0.01888120813774205,...</td>\n",
       "      <td>[-0.0006529823615933566, -0.006570183029020745...</td>\n",
       "      <td>[-0.00035617219723273994, -0.00355135690699015...</td>\n",
       "      <td>[0.0006529823615933566, 0.006451458963276498, ...</td>\n",
       "      <td>[0.00029681016436061664, 0.0029594640891584642...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CPSC_extra\\Q0004.mat</td>\n",
       "      <td>57</td>\n",
       "      <td>M</td>\n",
       "      <td>[164861001, 428750005]</td>\n",
       "      <td>[[-0.0004748962629769866, -0.00485386660839779...</td>\n",
       "      <td>[-0.0004748962629769866, -0.00485386660839779,...</td>\n",
       "      <td>[-0.0009497925259539732, -0.009589009151051332...</td>\n",
       "      <td>[-0.0004748962629769866, -0.004735142542653543...</td>\n",
       "      <td>[0.0007123443944654799, 0.0071620758468524375,...</td>\n",
       "      <td>[5.936203287212332e-05, 0.0005325307849595696,...</td>\n",
       "      <td>[-0.0007123443944654799, -0.007221437879724561...</td>\n",
       "      <td>[-0.001484050821803083, -0.0155096648402578, -...</td>\n",
       "      <td>[-0.00195894708478007, -0.020422893481527715, ...</td>\n",
       "      <td>[-0.0007717064273376033, -0.007991416796172624...</td>\n",
       "      <td>[-0.0013059647231867132, -0.01349653825527423,...</td>\n",
       "      <td>[-0.00106851659169822, -0.011307053082563828, ...</td>\n",
       "      <td>[-0.00106851659169822, -0.011010242918203211, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CPSC_extra\\Q0005.mat</td>\n",
       "      <td>51</td>\n",
       "      <td>F</td>\n",
       "      <td>[428750005]</td>\n",
       "      <td>[[0.0005936203287212333, 0.005978290211189051,...</td>\n",
       "      <td>[0.0005936203287212333, 0.005978290211189051, ...</td>\n",
       "      <td>[0.0012466026903145896, 0.013142093568931028, ...</td>\n",
       "      <td>[0.0007123443944654799, 0.007696334142701548, ...</td>\n",
       "      <td>[-0.0008904304930818499, -0.009293926497580257...</td>\n",
       "      <td>[-0.00011872406574424665, -0.00142123376715187...</td>\n",
       "      <td>[0.0009497925259539732, 0.010123267446900444, ...</td>\n",
       "      <td>[0.0055206690571074695, 0.057657961504720856, ...</td>\n",
       "      <td>[0.0017808609861636997, 0.018884663159521132, ...</td>\n",
       "      <td>[0.004333428399665003, 0.04546393295085426, 0....</td>\n",
       "      <td>[0.002968101643606166, 0.03125677781200409, 0....</td>\n",
       "      <td>[0.005223858892746853, 0.054639135382690274, 0...</td>\n",
       "      <td>[0.0026119294463734263, 0.027289886674909076, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3448</th>\n",
       "      <td>CPSC_extra\\Q3577.mat</td>\n",
       "      <td>61</td>\n",
       "      <td>M</td>\n",
       "      <td>[54329005, 428750005]</td>\n",
       "      <td>[[0.0018995850519079463, 0.018465673907637183,...</td>\n",
       "      <td>[0.0018995850519079463, 0.018465673907637183, ...</td>\n",
       "      <td>[-0.0022557572491406865, -0.02296682334058132,...</td>\n",
       "      <td>[-0.004155342301048633, -0.04143249724821851, ...</td>\n",
       "      <td>[0.00017808609861636997, 0.002191212683599942,...</td>\n",
       "      <td>[0.00302746367647829, 0.029889723545055723, 0....</td>\n",
       "      <td>[-0.0032055497750946597, -0.03219966029439991,...</td>\n",
       "      <td>[-0.020064367110777685, -0.1998223242956237, -...</td>\n",
       "      <td>[-0.012406664870273776, -0.12382432299256807, ...</td>\n",
       "      <td>[-0.00872621883220213, -0.08718633031987522, -...</td>\n",
       "      <td>[-0.01887712645333522, -0.1886374503005832, -0...</td>\n",
       "      <td>[-0.008251322569225143, -0.08233246371147744, ...</td>\n",
       "      <td>[-0.010566441851237951, -0.10547564563978556, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3449</th>\n",
       "      <td>CPSC_extra\\Q3578.mat</td>\n",
       "      <td>73</td>\n",
       "      <td>M</td>\n",
       "      <td>[164867002]</td>\n",
       "      <td>[[-0.00106851659169822, -0.010713432753842594,...</td>\n",
       "      <td>[-0.00106851659169822, -0.010713432753842594, ...</td>\n",
       "      <td>[-0.0022557572491406865, -0.02243256504473221,...</td>\n",
       "      <td>[-0.0011872406574424666, -0.011719132290889611...</td>\n",
       "      <td>[0.0016621369204194531, 0.016572998899287397, ...</td>\n",
       "      <td>[5.936203287212332e-05, 0.00047316875208744624...</td>\n",
       "      <td>[-0.0017214989532915764, -0.017046167651374844...</td>\n",
       "      <td>[0.005223858892746853, 0.05220529203493322, 0....</td>\n",
       "      <td>[0.0036804460380716465, 0.03699416486992557, 0...</td>\n",
       "      <td>[-0.004748962629769866, -0.04723270136079118, ...</td>\n",
       "      <td>[-0.00391789416956014, -0.03894620191114748, -...</td>\n",
       "      <td>[-0.004689600596897743, -0.04664080854295949, ...</td>\n",
       "      <td>[-0.004511514498281373, -0.044805768056592296,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3450</th>\n",
       "      <td>CPSC_extra\\Q3579.mat</td>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>[164865005]</td>\n",
       "      <td>[[-5.936203287212332e-05, -0.00053253078495956...</td>\n",
       "      <td>[-5.936203287212332e-05, -0.000532530784959569...</td>\n",
       "      <td>[0.005936203287212332, 0.059545453980402015, 0...</td>\n",
       "      <td>[0.00605492735295658, 0.060669877583193296, 0....</td>\n",
       "      <td>[-0.0029087396107340432, -0.029180834172369316...</td>\n",
       "      <td>[-0.00302746367647829, -0.03024589574228846, -...</td>\n",
       "      <td>[0.005995565320084456, 0.06013734679823372, 0....</td>\n",
       "      <td>[0.00463023856402562, 0.04587082962651143, 0.2...</td>\n",
       "      <td>[0.0035023599394552766, 0.03468422812058139, 0...</td>\n",
       "      <td>[0.00302746367647829, 0.030008447610799967, 0....</td>\n",
       "      <td>[0.00213703318339644, 0.021367503474813067, 0....</td>\n",
       "      <td>[0.0038585321366880164, 0.03859175722480428, 0...</td>\n",
       "      <td>[0.0024338433477570564, 0.024326967563971527, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3451</th>\n",
       "      <td>CPSC_extra\\Q3580.mat</td>\n",
       "      <td>73</td>\n",
       "      <td>F</td>\n",
       "      <td>[164867002]</td>\n",
       "      <td>[[0.0013059647231867132, 0.013437176222402107,...</td>\n",
       "      <td>[0.0013059647231867132, 0.013437176222402107, ...</td>\n",
       "      <td>[0.007301530043271169, 0.07488048774382254, 0....</td>\n",
       "      <td>[0.00605492735295658, 0.06197584230638001, 0.3...</td>\n",
       "      <td>[-0.004333428399665003, -0.044395416359156045,...</td>\n",
       "      <td>[-0.00231511928201281, -0.023736802257029378, ...</td>\n",
       "      <td>[0.006648547681677813, 0.06813221861618542, 0....</td>\n",
       "      <td>[-0.00017808609861636997, -0.00147886828913446...</td>\n",
       "      <td>[0.00747961614188754, 0.07766532075614371, 0.3...</td>\n",
       "      <td>[0.009676011358156102, 0.09998088924602119, 0....</td>\n",
       "      <td>[0.009913459489644595, 0.10276399474745283, 0....</td>\n",
       "      <td>[0.006826633780294182, 0.0709170516285066, 0.3...</td>\n",
       "      <td>[-0.0002374481314884933, -0.002486295337071018...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3452</th>\n",
       "      <td>CPSC_extra\\Q3581.mat</td>\n",
       "      <td>78</td>\n",
       "      <td>M</td>\n",
       "      <td>[164861001, 428750005]</td>\n",
       "      <td>[[5.936203287212332e-05, 0.0002950826534710763...</td>\n",
       "      <td>[5.936203287212332e-05, 0.0002950826534710763,...</td>\n",
       "      <td>[-0.02356672705023296, -0.2303512101151564, -1...</td>\n",
       "      <td>[-0.02356672705023296, -0.2300543999507958, -1...</td>\n",
       "      <td>[0.011753682508680419, 0.11505774474727873, 0....</td>\n",
       "      <td>[0.011813044541552542, 0.11517474130213344, 0....</td>\n",
       "      <td>[-0.02356672705023296, -0.23017312401654005, -...</td>\n",
       "      <td>[-0.01584966277685693, -0.1548298325859673, -0...</td>\n",
       "      <td>[-0.03318337637551694, -0.32172633210560936, -...</td>\n",
       "      <td>[-0.04475897278558099, -0.43637372515545186, -...</td>\n",
       "      <td>[-0.03721999461082132, -0.3638152667372002, -1...</td>\n",
       "      <td>[-0.03039336083052714, -0.2976471777384635, -1...</td>\n",
       "      <td>[-0.012347302837401652, -0.12008624243251383, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3453 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  filename age gender               diagnosis  \\\n",
       "0     CPSC_extra\\Q0001.mat  53      M  [164867002, 427084000]   \n",
       "1     CPSC_extra\\Q0002.mat  70      F             [164861001]   \n",
       "2     CPSC_extra\\Q0003.mat  55      M  [164867002, 428750005]   \n",
       "3     CPSC_extra\\Q0004.mat  57      M  [164861001, 428750005]   \n",
       "4     CPSC_extra\\Q0005.mat  51      F             [428750005]   \n",
       "...                    ...  ..    ...                     ...   \n",
       "3448  CPSC_extra\\Q3577.mat  61      M   [54329005, 428750005]   \n",
       "3449  CPSC_extra\\Q3578.mat  73      M             [164867002]   \n",
       "3450  CPSC_extra\\Q3579.mat  41      F             [164865005]   \n",
       "3451  CPSC_extra\\Q3580.mat  73      F             [164867002]   \n",
       "3452  CPSC_extra\\Q3581.mat  78      M  [164861001, 428750005]   \n",
       "\n",
       "                                             ecg_signal  \\\n",
       "0     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -5.93620328721...   \n",
       "1     [[0.0011278786245703433, 0.011542773703162784,...   \n",
       "2     [[-0.0027900155449897966, -0.02781896243808956...   \n",
       "3     [[-0.0004748962629769866, -0.00485386660839779...   \n",
       "4     [[0.0005936203287212333, 0.005978290211189051,...   \n",
       "...                                                 ...   \n",
       "3448  [[0.0018995850519079463, 0.018465673907637183,...   \n",
       "3449  [[-0.00106851659169822, -0.010713432753842594,...   \n",
       "3450  [[-5.936203287212332e-05, -0.00053253078495956...   \n",
       "3451  [[0.0013059647231867132, 0.013437176222402107,...   \n",
       "3452  [[5.936203287212332e-05, 0.0002950826534710763...   \n",
       "\n",
       "                                                 Lead I  \\\n",
       "0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -5.936203287212...   \n",
       "1     [0.0011278786245703433, 0.011542773703162784, ...   \n",
       "2     [-0.0027900155449897966, -0.027818962438089567...   \n",
       "3     [-0.0004748962629769866, -0.00485386660839779,...   \n",
       "4     [0.0005936203287212333, 0.005978290211189051, ...   \n",
       "...                                                 ...   \n",
       "3448  [0.0018995850519079463, 0.018465673907637183, ...   \n",
       "3449  [-0.00106851659169822, -0.010713432753842594, ...   \n",
       "3450  [-5.936203287212332e-05, -0.000532530784959569...   \n",
       "3451  [0.0013059647231867132, 0.013437176222402107, ...   \n",
       "3452  [5.936203287212332e-05, 0.0002950826534710763,...   \n",
       "\n",
       "                                                Lead II  \\\n",
       "0     [0.0005936203287212333, 0.006037652244061175, ...   \n",
       "1     [0.027603345285537352, 0.27422100573291114, 1....   \n",
       "2     [0.00035617219723273994, 0.003551356906990157,...   \n",
       "3     [-0.0009497925259539732, -0.009589009151051332...   \n",
       "4     [0.0012466026903145896, 0.013142093568931028, ...   \n",
       "...                                                 ...   \n",
       "3448  [-0.0022557572491406865, -0.02296682334058132,...   \n",
       "3449  [-0.0022557572491406865, -0.02243256504473221,...   \n",
       "3450  [0.005936203287212332, 0.059545453980402015, 0...   \n",
       "3451  [0.007301530043271169, 0.07488048774382254, 0....   \n",
       "3452  [-0.02356672705023296, -0.2303512101151564, -1...   \n",
       "\n",
       "                                               Lead III  \\\n",
       "0     [0.0005936203287212333, 0.006097014276933299, ...   \n",
       "1     [0.026475466660967006, 0.26267823202974827, 1....   \n",
       "2     [0.0031461877422225364, 0.03137031934507972, 0...   \n",
       "3     [-0.0004748962629769866, -0.004735142542653543...   \n",
       "4     [0.0007123443944654799, 0.007696334142701548, ...   \n",
       "...                                                 ...   \n",
       "3448  [-0.004155342301048633, -0.04143249724821851, ...   \n",
       "3449  [-0.0011872406574424666, -0.011719132290889611...   \n",
       "3450  [0.00605492735295658, 0.060669877583193296, 0....   \n",
       "3451  [0.00605492735295658, 0.06197584230638001, 0.3...   \n",
       "3452  [-0.02356672705023296, -0.2300543999507958, -1...   \n",
       "\n",
       "                                                    aVR  \\\n",
       "0     [-0.00029681016436061664, -0.00307818815490271...   \n",
       "1     [-0.014306249922181722, -0.14228999690020525, ...   \n",
       "2     [0.0012466026903145896, 0.012429749174465547, ...   \n",
       "3     [0.0007123443944654799, 0.0071620758468524375,...   \n",
       "4     [-0.0008904304930818499, -0.009293926497580257...   \n",
       "...                                                 ...   \n",
       "3448  [0.00017808609861636997, 0.002191212683599942,...   \n",
       "3449  [0.0016621369204194531, 0.016572998899287397, ...   \n",
       "3450  [-0.0029087396107340432, -0.029180834172369316...   \n",
       "3451  [-0.004333428399665003, -0.044395416359156045,...   \n",
       "3452  [0.011753682508680419, 0.11505774474727873, 0....   \n",
       "\n",
       "                                                    aVL  \\\n",
       "0     [-0.00029681016436061664, -0.00307818815490271...   \n",
       "1     [-0.012644113001762268, -0.12524210173794084, ...   \n",
       "2     [-0.002968101643606166, -0.029594640891584638,...   \n",
       "3     [5.936203287212332e-05, 0.0005325307849595696,...   \n",
       "4     [-0.00011872406574424665, -0.00142123376715187...   \n",
       "...                                                 ...   \n",
       "3448  [0.00302746367647829, 0.029889723545055723, 0....   \n",
       "3449  [5.936203287212332e-05, 0.00047316875208744624...   \n",
       "3450  [-0.00302746367647829, -0.03024589574228846, -...   \n",
       "3451  [-0.00231511928201281, -0.023736802257029378, ...   \n",
       "3452  [0.011813044541552542, 0.11517474130213344, 0....   \n",
       "\n",
       "                                                    aVF  \\\n",
       "0     [0.0006529823615933566, 0.006629545061892868, ...   \n",
       "1     [0.02700972495681611, 0.26818335348884986, 1.3...   \n",
       "2     [0.0017808609861636997, 0.01775678453495079, 0...   \n",
       "3     [-0.0007123443944654799, -0.007221437879724561...   \n",
       "4     [0.0009497925259539732, 0.010123267446900444, ...   \n",
       "...                                                 ...   \n",
       "3448  [-0.0032055497750946597, -0.03219966029439991,...   \n",
       "3449  [-0.0017214989532915764, -0.017046167651374844...   \n",
       "3450  [0.005995565320084456, 0.06013734679823372, 0....   \n",
       "3451  [0.006648547681677813, 0.06813221861618542, 0....   \n",
       "3452  [-0.02356672705023296, -0.23017312401654005, -...   \n",
       "\n",
       "                                                     V1  \\\n",
       "0     [0.003086825709350413, 0.03202502921756262, 0....   \n",
       "1     [0.0026712914792455496, 0.02693198696678679, 0...   \n",
       "2     [-0.0008310684602097266, -0.008405223515387946...   \n",
       "3     [-0.001484050821803083, -0.0155096648402578, -...   \n",
       "4     [0.0055206690571074695, 0.057657961504720856, ...   \n",
       "...                                                 ...   \n",
       "3448  [-0.020064367110777685, -0.1998223242956237, -...   \n",
       "3449  [0.005223858892746853, 0.05220529203493322, 0....   \n",
       "3450  [0.00463023856402562, 0.04587082962651143, 0.2...   \n",
       "3451  [-0.00017808609861636997, -0.00147886828913446...   \n",
       "3452  [-0.01584966277685693, -0.1548298325859673, -0...   \n",
       "\n",
       "                                                     V2  \\\n",
       "0     [0.0026119294463734263, 0.027052438543420584, ...   \n",
       "1     [0.0007717064273376033, 0.00811014086191687, 0...   \n",
       "2     [-0.0018995850519079463, -0.01888120813774205,...   \n",
       "3     [-0.00195894708478007, -0.020422893481527715, ...   \n",
       "4     [0.0017808609861636997, 0.018884663159521132, ...   \n",
       "...                                                 ...   \n",
       "3448  [-0.012406664870273776, -0.12382432299256807, ...   \n",
       "3449  [0.0036804460380716465, 0.03699416486992557, 0...   \n",
       "3450  [0.0035023599394552766, 0.03468422812058139, 0...   \n",
       "3451  [0.00747961614188754, 0.07766532075614371, 0.3...   \n",
       "3452  [-0.03318337637551694, -0.32172633210560936, -...   \n",
       "\n",
       "                                                     V3  \\\n",
       "0     [0.0010091545588260965, 0.010240264001755145, ...   \n",
       "1     [0.0013653267560588367, 0.013850982941617431, ...   \n",
       "2     [-0.0006529823615933566, -0.006570183029020745...   \n",
       "3     [-0.0007717064273376033, -0.007991416796172624...   \n",
       "4     [0.004333428399665003, 0.04546393295085426, 0....   \n",
       "...                                                 ...   \n",
       "3448  [-0.00872621883220213, -0.08718633031987522, -...   \n",
       "3449  [-0.004748962629769866, -0.04723270136079118, ...   \n",
       "3450  [0.00302746367647829, 0.030008447610799967, 0....   \n",
       "3451  [0.009676011358156102, 0.09998088924602119, 0....   \n",
       "3452  [-0.04475897278558099, -0.43637372515545186, -...   \n",
       "\n",
       "                                                     V4  \\\n",
       "0     [0.004452152465409249, 0.04605409825779641, 0....   \n",
       "1     [0.0035023599394552766, 0.03539657251504687, 0...   \n",
       "2     [-0.00035617219723273994, -0.00355135690699015...   \n",
       "3     [-0.0013059647231867132, -0.01349653825527423,...   \n",
       "4     [0.002968101643606166, 0.03125677781200409, 0....   \n",
       "...                                                 ...   \n",
       "3448  [-0.01887712645333522, -0.1886374503005832, -0...   \n",
       "3449  [-0.00391789416956014, -0.03894620191114748, -...   \n",
       "3450  [0.00213703318339644, 0.021367503474813067, 0....   \n",
       "3451  [0.009913459489644595, 0.10276399474745283, 0....   \n",
       "3452  [-0.03721999461082132, -0.3638152667372002, -1...   \n",
       "\n",
       "                                                     V5  \\\n",
       "0     [0.0009497925259539732, 0.009589009151051332, ...   \n",
       "1     [-0.019767556946417065, -0.1963879639434882, -...   \n",
       "2     [0.0006529823615933566, 0.006451458963276498, ...   \n",
       "3     [-0.00106851659169822, -0.011307053082563828, ...   \n",
       "4     [0.005223858892746853, 0.054639135382690274, 0...   \n",
       "...                                                 ...   \n",
       "3448  [-0.008251322569225143, -0.08233246371147744, ...   \n",
       "3449  [-0.004689600596897743, -0.04664080854295949, ...   \n",
       "3450  [0.0038585321366880164, 0.03859175722480428, 0...   \n",
       "3451  [0.006826633780294182, 0.0709170516285066, 0.3...   \n",
       "3452  [-0.03039336083052714, -0.2976471777384635, -1...   \n",
       "\n",
       "                                                     V6  \n",
       "0     [0.00053425829584911, 0.005327035360485236, 0....  \n",
       "1     [-0.009023028996562746, -0.08854301952148638, ...  \n",
       "2     [0.00029681016436061664, 0.0029594640891584642...  \n",
       "3     [-0.00106851659169822, -0.011010242918203211, ...  \n",
       "4     [0.0026119294463734263, 0.027289886674909076, ...  \n",
       "...                                                 ...  \n",
       "3448  [-0.010566441851237951, -0.10547564563978556, ...  \n",
       "3449  [-0.004511514498281373, -0.044805768056592296,...  \n",
       "3450  [0.0024338433477570564, 0.024326967563971527, ...  \n",
       "3451  [-0.0002374481314884933, -0.002486295337071018...  \n",
       "3452  [-0.012347302837401652, -0.12008624243251383, ...  \n",
       "\n",
       "[3453 rows x 17 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>ecg_signal</th>\n",
       "      <th>Lead I</th>\n",
       "      <th>Lead II</th>\n",
       "      <th>Lead III</th>\n",
       "      <th>aVR</th>\n",
       "      <th>aVL</th>\n",
       "      <th>aVF</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CPSC_extra\\Q0001.mat</td>\n",
       "      <td>53</td>\n",
       "      <td>M</td>\n",
       "      <td>[164867002, 427084000]</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -5.93620328721...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -5.936203287212...</td>\n",
       "      <td>[0.0005936203287212333, 0.006037652244061175, ...</td>\n",
       "      <td>[0.0005936203287212333, 0.006097014276933299, ...</td>\n",
       "      <td>[-0.00029681016436061664, -0.00307818815490271...</td>\n",
       "      <td>[-0.00029681016436061664, -0.00307818815490271...</td>\n",
       "      <td>[0.0006529823615933566, 0.006629545061892868, ...</td>\n",
       "      <td>[0.003086825709350413, 0.03202502921756262, 0....</td>\n",
       "      <td>[0.0026119294463734263, 0.027052438543420584, ...</td>\n",
       "      <td>[0.0010091545588260965, 0.010240264001755145, ...</td>\n",
       "      <td>[0.004452152465409249, 0.04605409825779641, 0....</td>\n",
       "      <td>[0.0009497925259539732, 0.009589009151051332, ...</td>\n",
       "      <td>[0.00053425829584911, 0.005327035360485236, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CPSC_extra\\Q0002.mat</td>\n",
       "      <td>70</td>\n",
       "      <td>F</td>\n",
       "      <td>[164861001]</td>\n",
       "      <td>[[0.0011278786245703433, 0.011542773703162784,...</td>\n",
       "      <td>[0.0011278786245703433, 0.011542773703162784, ...</td>\n",
       "      <td>[0.027603345285537352, 0.27422100573291114, 1....</td>\n",
       "      <td>[0.026475466660967006, 0.26267823202974827, 1....</td>\n",
       "      <td>[-0.014306249922181722, -0.14228999690020525, ...</td>\n",
       "      <td>[-0.012644113001762268, -0.12524210173794084, ...</td>\n",
       "      <td>[0.02700972495681611, 0.26818335348884986, 1.3...</td>\n",
       "      <td>[0.0026712914792455496, 0.02693198696678679, 0...</td>\n",
       "      <td>[0.0007717064273376033, 0.00811014086191687, 0...</td>\n",
       "      <td>[0.0013653267560588367, 0.013850982941617431, ...</td>\n",
       "      <td>[0.0035023599394552766, 0.03539657251504687, 0...</td>\n",
       "      <td>[-0.019767556946417065, -0.1963879639434882, -...</td>\n",
       "      <td>[-0.009023028996562746, -0.08854301952148638, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CPSC_extra\\Q0003.mat</td>\n",
       "      <td>55</td>\n",
       "      <td>M</td>\n",
       "      <td>[164867002, 428750005]</td>\n",
       "      <td>[[-0.0027900155449897966, -0.02781896243808956...</td>\n",
       "      <td>[-0.0027900155449897966, -0.027818962438089567...</td>\n",
       "      <td>[0.00035617219723273994, 0.003551356906990157,...</td>\n",
       "      <td>[0.0031461877422225364, 0.03137031934507972, 0...</td>\n",
       "      <td>[0.0012466026903145896, 0.012429749174465547, ...</td>\n",
       "      <td>[-0.002968101643606166, -0.029594640891584638,...</td>\n",
       "      <td>[0.0017808609861636997, 0.01775678453495079, 0...</td>\n",
       "      <td>[-0.0008310684602097266, -0.008405223515387946...</td>\n",
       "      <td>[-0.0018995850519079463, -0.01888120813774205,...</td>\n",
       "      <td>[-0.0006529823615933566, -0.006570183029020745...</td>\n",
       "      <td>[-0.00035617219723273994, -0.00355135690699015...</td>\n",
       "      <td>[0.0006529823615933566, 0.006451458963276498, ...</td>\n",
       "      <td>[0.00029681016436061664, 0.0029594640891584642...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CPSC_extra\\Q0004.mat</td>\n",
       "      <td>57</td>\n",
       "      <td>M</td>\n",
       "      <td>[164861001, 428750005]</td>\n",
       "      <td>[[-0.0004748962629769866, -0.00485386660839779...</td>\n",
       "      <td>[-0.0004748962629769866, -0.00485386660839779,...</td>\n",
       "      <td>[-0.0009497925259539732, -0.009589009151051332...</td>\n",
       "      <td>[-0.0004748962629769866, -0.004735142542653543...</td>\n",
       "      <td>[0.0007123443944654799, 0.0071620758468524375,...</td>\n",
       "      <td>[5.936203287212332e-05, 0.0005325307849595696,...</td>\n",
       "      <td>[-0.0007123443944654799, -0.007221437879724561...</td>\n",
       "      <td>[-0.001484050821803083, -0.0155096648402578, -...</td>\n",
       "      <td>[-0.00195894708478007, -0.020422893481527715, ...</td>\n",
       "      <td>[-0.0007717064273376033, -0.007991416796172624...</td>\n",
       "      <td>[-0.0013059647231867132, -0.01349653825527423,...</td>\n",
       "      <td>[-0.00106851659169822, -0.011307053082563828, ...</td>\n",
       "      <td>[-0.00106851659169822, -0.011010242918203211, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CPSC_extra\\Q0005.mat</td>\n",
       "      <td>51</td>\n",
       "      <td>F</td>\n",
       "      <td>[428750005]</td>\n",
       "      <td>[[0.0005936203287212333, 0.005978290211189051,...</td>\n",
       "      <td>[0.0005936203287212333, 0.005978290211189051, ...</td>\n",
       "      <td>[0.0012466026903145896, 0.013142093568931028, ...</td>\n",
       "      <td>[0.0007123443944654799, 0.007696334142701548, ...</td>\n",
       "      <td>[-0.0008904304930818499, -0.009293926497580257...</td>\n",
       "      <td>[-0.00011872406574424665, -0.00142123376715187...</td>\n",
       "      <td>[0.0009497925259539732, 0.010123267446900444, ...</td>\n",
       "      <td>[0.0055206690571074695, 0.057657961504720856, ...</td>\n",
       "      <td>[0.0017808609861636997, 0.018884663159521132, ...</td>\n",
       "      <td>[0.004333428399665003, 0.04546393295085426, 0....</td>\n",
       "      <td>[0.002968101643606166, 0.03125677781200409, 0....</td>\n",
       "      <td>[0.005223858892746853, 0.054639135382690274, 0...</td>\n",
       "      <td>[0.0026119294463734263, 0.027289886674909076, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3448</th>\n",
       "      <td>CPSC_extra\\Q3577.mat</td>\n",
       "      <td>61</td>\n",
       "      <td>M</td>\n",
       "      <td>[54329005, 428750005]</td>\n",
       "      <td>[[0.0018995850519079463, 0.018465673907637183,...</td>\n",
       "      <td>[0.0018995850519079463, 0.018465673907637183, ...</td>\n",
       "      <td>[-0.0022557572491406865, -0.02296682334058132,...</td>\n",
       "      <td>[-0.004155342301048633, -0.04143249724821851, ...</td>\n",
       "      <td>[0.00017808609861636997, 0.002191212683599942,...</td>\n",
       "      <td>[0.00302746367647829, 0.029889723545055723, 0....</td>\n",
       "      <td>[-0.0032055497750946597, -0.03219966029439991,...</td>\n",
       "      <td>[-0.020064367110777685, -0.1998223242956237, -...</td>\n",
       "      <td>[-0.012406664870273776, -0.12382432299256807, ...</td>\n",
       "      <td>[-0.00872621883220213, -0.08718633031987522, -...</td>\n",
       "      <td>[-0.01887712645333522, -0.1886374503005832, -0...</td>\n",
       "      <td>[-0.008251322569225143, -0.08233246371147744, ...</td>\n",
       "      <td>[-0.010566441851237951, -0.10547564563978556, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3449</th>\n",
       "      <td>CPSC_extra\\Q3578.mat</td>\n",
       "      <td>73</td>\n",
       "      <td>M</td>\n",
       "      <td>[164867002]</td>\n",
       "      <td>[[-0.00106851659169822, -0.010713432753842594,...</td>\n",
       "      <td>[-0.00106851659169822, -0.010713432753842594, ...</td>\n",
       "      <td>[-0.0022557572491406865, -0.02243256504473221,...</td>\n",
       "      <td>[-0.0011872406574424666, -0.011719132290889611...</td>\n",
       "      <td>[0.0016621369204194531, 0.016572998899287397, ...</td>\n",
       "      <td>[5.936203287212332e-05, 0.00047316875208744624...</td>\n",
       "      <td>[-0.0017214989532915764, -0.017046167651374844...</td>\n",
       "      <td>[0.005223858892746853, 0.05220529203493322, 0....</td>\n",
       "      <td>[0.0036804460380716465, 0.03699416486992557, 0...</td>\n",
       "      <td>[-0.004748962629769866, -0.04723270136079118, ...</td>\n",
       "      <td>[-0.00391789416956014, -0.03894620191114748, -...</td>\n",
       "      <td>[-0.004689600596897743, -0.04664080854295949, ...</td>\n",
       "      <td>[-0.004511514498281373, -0.044805768056592296,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3450</th>\n",
       "      <td>CPSC_extra\\Q3579.mat</td>\n",
       "      <td>41</td>\n",
       "      <td>F</td>\n",
       "      <td>[164865005]</td>\n",
       "      <td>[[-5.936203287212332e-05, -0.00053253078495956...</td>\n",
       "      <td>[-5.936203287212332e-05, -0.000532530784959569...</td>\n",
       "      <td>[0.005936203287212332, 0.059545453980402015, 0...</td>\n",
       "      <td>[0.00605492735295658, 0.060669877583193296, 0....</td>\n",
       "      <td>[-0.0029087396107340432, -0.029180834172369316...</td>\n",
       "      <td>[-0.00302746367647829, -0.03024589574228846, -...</td>\n",
       "      <td>[0.005995565320084456, 0.06013734679823372, 0....</td>\n",
       "      <td>[0.00463023856402562, 0.04587082962651143, 0.2...</td>\n",
       "      <td>[0.0035023599394552766, 0.03468422812058139, 0...</td>\n",
       "      <td>[0.00302746367647829, 0.030008447610799967, 0....</td>\n",
       "      <td>[0.00213703318339644, 0.021367503474813067, 0....</td>\n",
       "      <td>[0.0038585321366880164, 0.03859175722480428, 0...</td>\n",
       "      <td>[0.0024338433477570564, 0.024326967563971527, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3451</th>\n",
       "      <td>CPSC_extra\\Q3580.mat</td>\n",
       "      <td>73</td>\n",
       "      <td>F</td>\n",
       "      <td>[164867002]</td>\n",
       "      <td>[[0.0013059647231867132, 0.013437176222402107,...</td>\n",
       "      <td>[0.0013059647231867132, 0.013437176222402107, ...</td>\n",
       "      <td>[0.007301530043271169, 0.07488048774382254, 0....</td>\n",
       "      <td>[0.00605492735295658, 0.06197584230638001, 0.3...</td>\n",
       "      <td>[-0.004333428399665003, -0.044395416359156045,...</td>\n",
       "      <td>[-0.00231511928201281, -0.023736802257029378, ...</td>\n",
       "      <td>[0.006648547681677813, 0.06813221861618542, 0....</td>\n",
       "      <td>[-0.00017808609861636997, -0.00147886828913446...</td>\n",
       "      <td>[0.00747961614188754, 0.07766532075614371, 0.3...</td>\n",
       "      <td>[0.009676011358156102, 0.09998088924602119, 0....</td>\n",
       "      <td>[0.009913459489644595, 0.10276399474745283, 0....</td>\n",
       "      <td>[0.006826633780294182, 0.0709170516285066, 0.3...</td>\n",
       "      <td>[-0.0002374481314884933, -0.002486295337071018...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3452</th>\n",
       "      <td>CPSC_extra\\Q3581.mat</td>\n",
       "      <td>78</td>\n",
       "      <td>M</td>\n",
       "      <td>[164861001, 428750005]</td>\n",
       "      <td>[[5.936203287212332e-05, 0.0002950826534710763...</td>\n",
       "      <td>[5.936203287212332e-05, 0.0002950826534710763,...</td>\n",
       "      <td>[-0.02356672705023296, -0.2303512101151564, -1...</td>\n",
       "      <td>[-0.02356672705023296, -0.2300543999507958, -1...</td>\n",
       "      <td>[0.011753682508680419, 0.11505774474727873, 0....</td>\n",
       "      <td>[0.011813044541552542, 0.11517474130213344, 0....</td>\n",
       "      <td>[-0.02356672705023296, -0.23017312401654005, -...</td>\n",
       "      <td>[-0.01584966277685693, -0.1548298325859673, -0...</td>\n",
       "      <td>[-0.03318337637551694, -0.32172633210560936, -...</td>\n",
       "      <td>[-0.04475897278558099, -0.43637372515545186, -...</td>\n",
       "      <td>[-0.03721999461082132, -0.3638152667372002, -1...</td>\n",
       "      <td>[-0.03039336083052714, -0.2976471777384635, -1...</td>\n",
       "      <td>[-0.012347302837401652, -0.12008624243251383, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3453 rows × 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  filename age gender               diagnosis  \\\n",
       "0     CPSC_extra\\Q0001.mat  53      M  [164867002, 427084000]   \n",
       "1     CPSC_extra\\Q0002.mat  70      F             [164861001]   \n",
       "2     CPSC_extra\\Q0003.mat  55      M  [164867002, 428750005]   \n",
       "3     CPSC_extra\\Q0004.mat  57      M  [164861001, 428750005]   \n",
       "4     CPSC_extra\\Q0005.mat  51      F             [428750005]   \n",
       "...                    ...  ..    ...                     ...   \n",
       "3448  CPSC_extra\\Q3577.mat  61      M   [54329005, 428750005]   \n",
       "3449  CPSC_extra\\Q3578.mat  73      M             [164867002]   \n",
       "3450  CPSC_extra\\Q3579.mat  41      F             [164865005]   \n",
       "3451  CPSC_extra\\Q3580.mat  73      F             [164867002]   \n",
       "3452  CPSC_extra\\Q3581.mat  78      M  [164861001, 428750005]   \n",
       "\n",
       "                                             ecg_signal  \\\n",
       "0     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -5.93620328721...   \n",
       "1     [[0.0011278786245703433, 0.011542773703162784,...   \n",
       "2     [[-0.0027900155449897966, -0.02781896243808956...   \n",
       "3     [[-0.0004748962629769866, -0.00485386660839779...   \n",
       "4     [[0.0005936203287212333, 0.005978290211189051,...   \n",
       "...                                                 ...   \n",
       "3448  [[0.0018995850519079463, 0.018465673907637183,...   \n",
       "3449  [[-0.00106851659169822, -0.010713432753842594,...   \n",
       "3450  [[-5.936203287212332e-05, -0.00053253078495956...   \n",
       "3451  [[0.0013059647231867132, 0.013437176222402107,...   \n",
       "3452  [[5.936203287212332e-05, 0.0002950826534710763...   \n",
       "\n",
       "                                                 Lead I  \\\n",
       "0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -5.936203287212...   \n",
       "1     [0.0011278786245703433, 0.011542773703162784, ...   \n",
       "2     [-0.0027900155449897966, -0.027818962438089567...   \n",
       "3     [-0.0004748962629769866, -0.00485386660839779,...   \n",
       "4     [0.0005936203287212333, 0.005978290211189051, ...   \n",
       "...                                                 ...   \n",
       "3448  [0.0018995850519079463, 0.018465673907637183, ...   \n",
       "3449  [-0.00106851659169822, -0.010713432753842594, ...   \n",
       "3450  [-5.936203287212332e-05, -0.000532530784959569...   \n",
       "3451  [0.0013059647231867132, 0.013437176222402107, ...   \n",
       "3452  [5.936203287212332e-05, 0.0002950826534710763,...   \n",
       "\n",
       "                                                Lead II  \\\n",
       "0     [0.0005936203287212333, 0.006037652244061175, ...   \n",
       "1     [0.027603345285537352, 0.27422100573291114, 1....   \n",
       "2     [0.00035617219723273994, 0.003551356906990157,...   \n",
       "3     [-0.0009497925259539732, -0.009589009151051332...   \n",
       "4     [0.0012466026903145896, 0.013142093568931028, ...   \n",
       "...                                                 ...   \n",
       "3448  [-0.0022557572491406865, -0.02296682334058132,...   \n",
       "3449  [-0.0022557572491406865, -0.02243256504473221,...   \n",
       "3450  [0.005936203287212332, 0.059545453980402015, 0...   \n",
       "3451  [0.007301530043271169, 0.07488048774382254, 0....   \n",
       "3452  [-0.02356672705023296, -0.2303512101151564, -1...   \n",
       "\n",
       "                                               Lead III  \\\n",
       "0     [0.0005936203287212333, 0.006097014276933299, ...   \n",
       "1     [0.026475466660967006, 0.26267823202974827, 1....   \n",
       "2     [0.0031461877422225364, 0.03137031934507972, 0...   \n",
       "3     [-0.0004748962629769866, -0.004735142542653543...   \n",
       "4     [0.0007123443944654799, 0.007696334142701548, ...   \n",
       "...                                                 ...   \n",
       "3448  [-0.004155342301048633, -0.04143249724821851, ...   \n",
       "3449  [-0.0011872406574424666, -0.011719132290889611...   \n",
       "3450  [0.00605492735295658, 0.060669877583193296, 0....   \n",
       "3451  [0.00605492735295658, 0.06197584230638001, 0.3...   \n",
       "3452  [-0.02356672705023296, -0.2300543999507958, -1...   \n",
       "\n",
       "                                                    aVR  \\\n",
       "0     [-0.00029681016436061664, -0.00307818815490271...   \n",
       "1     [-0.014306249922181722, -0.14228999690020525, ...   \n",
       "2     [0.0012466026903145896, 0.012429749174465547, ...   \n",
       "3     [0.0007123443944654799, 0.0071620758468524375,...   \n",
       "4     [-0.0008904304930818499, -0.009293926497580257...   \n",
       "...                                                 ...   \n",
       "3448  [0.00017808609861636997, 0.002191212683599942,...   \n",
       "3449  [0.0016621369204194531, 0.016572998899287397, ...   \n",
       "3450  [-0.0029087396107340432, -0.029180834172369316...   \n",
       "3451  [-0.004333428399665003, -0.044395416359156045,...   \n",
       "3452  [0.011753682508680419, 0.11505774474727873, 0....   \n",
       "\n",
       "                                                    aVL  \\\n",
       "0     [-0.00029681016436061664, -0.00307818815490271...   \n",
       "1     [-0.012644113001762268, -0.12524210173794084, ...   \n",
       "2     [-0.002968101643606166, -0.029594640891584638,...   \n",
       "3     [5.936203287212332e-05, 0.0005325307849595696,...   \n",
       "4     [-0.00011872406574424665, -0.00142123376715187...   \n",
       "...                                                 ...   \n",
       "3448  [0.00302746367647829, 0.029889723545055723, 0....   \n",
       "3449  [5.936203287212332e-05, 0.00047316875208744624...   \n",
       "3450  [-0.00302746367647829, -0.03024589574228846, -...   \n",
       "3451  [-0.00231511928201281, -0.023736802257029378, ...   \n",
       "3452  [0.011813044541552542, 0.11517474130213344, 0....   \n",
       "\n",
       "                                                    aVF  \\\n",
       "0     [0.0006529823615933566, 0.006629545061892868, ...   \n",
       "1     [0.02700972495681611, 0.26818335348884986, 1.3...   \n",
       "2     [0.0017808609861636997, 0.01775678453495079, 0...   \n",
       "3     [-0.0007123443944654799, -0.007221437879724561...   \n",
       "4     [0.0009497925259539732, 0.010123267446900444, ...   \n",
       "...                                                 ...   \n",
       "3448  [-0.0032055497750946597, -0.03219966029439991,...   \n",
       "3449  [-0.0017214989532915764, -0.017046167651374844...   \n",
       "3450  [0.005995565320084456, 0.06013734679823372, 0....   \n",
       "3451  [0.006648547681677813, 0.06813221861618542, 0....   \n",
       "3452  [-0.02356672705023296, -0.23017312401654005, -...   \n",
       "\n",
       "                                                     V1  \\\n",
       "0     [0.003086825709350413, 0.03202502921756262, 0....   \n",
       "1     [0.0026712914792455496, 0.02693198696678679, 0...   \n",
       "2     [-0.0008310684602097266, -0.008405223515387946...   \n",
       "3     [-0.001484050821803083, -0.0155096648402578, -...   \n",
       "4     [0.0055206690571074695, 0.057657961504720856, ...   \n",
       "...                                                 ...   \n",
       "3448  [-0.020064367110777685, -0.1998223242956237, -...   \n",
       "3449  [0.005223858892746853, 0.05220529203493322, 0....   \n",
       "3450  [0.00463023856402562, 0.04587082962651143, 0.2...   \n",
       "3451  [-0.00017808609861636997, -0.00147886828913446...   \n",
       "3452  [-0.01584966277685693, -0.1548298325859673, -0...   \n",
       "\n",
       "                                                     V2  \\\n",
       "0     [0.0026119294463734263, 0.027052438543420584, ...   \n",
       "1     [0.0007717064273376033, 0.00811014086191687, 0...   \n",
       "2     [-0.0018995850519079463, -0.01888120813774205,...   \n",
       "3     [-0.00195894708478007, -0.020422893481527715, ...   \n",
       "4     [0.0017808609861636997, 0.018884663159521132, ...   \n",
       "...                                                 ...   \n",
       "3448  [-0.012406664870273776, -0.12382432299256807, ...   \n",
       "3449  [0.0036804460380716465, 0.03699416486992557, 0...   \n",
       "3450  [0.0035023599394552766, 0.03468422812058139, 0...   \n",
       "3451  [0.00747961614188754, 0.07766532075614371, 0.3...   \n",
       "3452  [-0.03318337637551694, -0.32172633210560936, -...   \n",
       "\n",
       "                                                     V3  \\\n",
       "0     [0.0010091545588260965, 0.010240264001755145, ...   \n",
       "1     [0.0013653267560588367, 0.013850982941617431, ...   \n",
       "2     [-0.0006529823615933566, -0.006570183029020745...   \n",
       "3     [-0.0007717064273376033, -0.007991416796172624...   \n",
       "4     [0.004333428399665003, 0.04546393295085426, 0....   \n",
       "...                                                 ...   \n",
       "3448  [-0.00872621883220213, -0.08718633031987522, -...   \n",
       "3449  [-0.004748962629769866, -0.04723270136079118, ...   \n",
       "3450  [0.00302746367647829, 0.030008447610799967, 0....   \n",
       "3451  [0.009676011358156102, 0.09998088924602119, 0....   \n",
       "3452  [-0.04475897278558099, -0.43637372515545186, -...   \n",
       "\n",
       "                                                     V4  \\\n",
       "0     [0.004452152465409249, 0.04605409825779641, 0....   \n",
       "1     [0.0035023599394552766, 0.03539657251504687, 0...   \n",
       "2     [-0.00035617219723273994, -0.00355135690699015...   \n",
       "3     [-0.0013059647231867132, -0.01349653825527423,...   \n",
       "4     [0.002968101643606166, 0.03125677781200409, 0....   \n",
       "...                                                 ...   \n",
       "3448  [-0.01887712645333522, -0.1886374503005832, -0...   \n",
       "3449  [-0.00391789416956014, -0.03894620191114748, -...   \n",
       "3450  [0.00213703318339644, 0.021367503474813067, 0....   \n",
       "3451  [0.009913459489644595, 0.10276399474745283, 0....   \n",
       "3452  [-0.03721999461082132, -0.3638152667372002, -1...   \n",
       "\n",
       "                                                     V5  \\\n",
       "0     [0.0009497925259539732, 0.009589009151051332, ...   \n",
       "1     [-0.019767556946417065, -0.1963879639434882, -...   \n",
       "2     [0.0006529823615933566, 0.006451458963276498, ...   \n",
       "3     [-0.00106851659169822, -0.011307053082563828, ...   \n",
       "4     [0.005223858892746853, 0.054639135382690274, 0...   \n",
       "...                                                 ...   \n",
       "3448  [-0.008251322569225143, -0.08233246371147744, ...   \n",
       "3449  [-0.004689600596897743, -0.04664080854295949, ...   \n",
       "3450  [0.0038585321366880164, 0.03859175722480428, 0...   \n",
       "3451  [0.006826633780294182, 0.0709170516285066, 0.3...   \n",
       "3452  [-0.03039336083052714, -0.2976471777384635, -1...   \n",
       "\n",
       "                                                     V6  \n",
       "0     [0.00053425829584911, 0.005327035360485236, 0....  \n",
       "1     [-0.009023028996562746, -0.08854301952148638, ...  \n",
       "2     [0.00029681016436061664, 0.0029594640891584642...  \n",
       "3     [-0.00106851659169822, -0.011010242918203211, ...  \n",
       "4     [0.0026119294463734263, 0.027289886674909076, ...  \n",
       "...                                                 ...  \n",
       "3448  [-0.010566441851237951, -0.10547564563978556, ...  \n",
       "3449  [-0.004511514498281373, -0.044805768056592296,...  \n",
       "3450  [0.0024338433477570564, 0.024326967563971527, ...  \n",
       "3451  [-0.0002374481314884933, -0.002486295337071018...  \n",
       "3452  [-0.012347302837401652, -0.12008624243251383, ...  \n",
       "\n",
       "[3453 rows x 17 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "copy_df = df\n",
    "copy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = utils.Encoder(copy_df,mappings_scored)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The classes we will look at are encoded as SNOMED CT codes:\n",
      "['10370003' '111288001' '11157007' '111975006' '164861001' '164865005'\n",
      " '164867002' '164873001' '164889003' '164890007' '164895002' '164896001'\n",
      " '164909002' '164917005' '164921003' '164930006' '164931005' '164934002'\n",
      " '164937009' '17338001' '195042002' '195060002' '195080001' '195126007'\n",
      " '233917008' '251120003' '251164006' '251170000' '251180001' '251259000'\n",
      " '266249003' '270492004' '27885002' '284470004' '29320008' '370365005'\n",
      " '413444003' '413844008' '426177001' '426627000' '426648003' '426749004'\n",
      " '426761007' '426783006' '426995002' '427084000' '427172004' '427393009'\n",
      " '428750005' '429622005' '446358003' '446813000' '47665007' '49578007'\n",
      " '54329005' '55930002' '59118001' '59931005' '63593006' '65778007'\n",
      " '67741000119109' '698252002' '704997005' '713422000' '713426002'\n",
      " '713427006' '74615001' '75532003' '77867006' '81898007' '82226007'\n",
      " '89792004']\n",
      "classes: 71\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>ecg_signal</th>\n",
       "      <th>Lead I</th>\n",
       "      <th>Lead II</th>\n",
       "      <th>Lead III</th>\n",
       "      <th>aVR</th>\n",
       "      <th>aVL</th>\n",
       "      <th>aVF</th>\n",
       "      <th>...</th>\n",
       "      <th>427084000</th>\n",
       "      <th>427172004</th>\n",
       "      <th>427393009</th>\n",
       "      <th>47665007</th>\n",
       "      <th>59118001</th>\n",
       "      <th>59931005</th>\n",
       "      <th>63593006</th>\n",
       "      <th>698252002</th>\n",
       "      <th>713426002</th>\n",
       "      <th>713427006</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CPSC_extra\\Q0001.mat</td>\n",
       "      <td>53</td>\n",
       "      <td>M</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -5.93620328721...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -5.936203287212...</td>\n",
       "      <td>[0.0005936203287212333, 0.006037652244061175, ...</td>\n",
       "      <td>[0.0005936203287212333, 0.006097014276933299, ...</td>\n",
       "      <td>[-0.00029681016436061664, -0.00307818815490271...</td>\n",
       "      <td>[-0.00029681016436061664, -0.00307818815490271...</td>\n",
       "      <td>[0.0006529823615933566, 0.006629545061892868, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CPSC_extra\\Q0010.mat</td>\n",
       "      <td>72</td>\n",
       "      <td>M</td>\n",
       "      <td>[[0.002374481314884933, 0.023794436779011958, ...</td>\n",
       "      <td>[0.002374481314884933, 0.023794436779011958, 0...</td>\n",
       "      <td>[0.00029681016436061664, 0.0028407400234142176...</td>\n",
       "      <td>[-0.0020776711505243167, -0.020953696755597745...</td>\n",
       "      <td>[-0.0013059647231867132, -0.013021641992297241...</td>\n",
       "      <td>[0.0021963952162685632, 0.022078120358389002, ...</td>\n",
       "      <td>[-0.0008904304930818499, -0.009056478366091763...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CPSC_extra\\Q0012.mat</td>\n",
       "      <td>79</td>\n",
       "      <td>F</td>\n",
       "      <td>[[0.0011278786245703433, 0.011542773703162784,...</td>\n",
       "      <td>[0.0011278786245703433, 0.011542773703162784, ...</td>\n",
       "      <td>[0.00011872406574424665, 0.0010056995370470159...</td>\n",
       "      <td>[-0.0009497925259539732, -0.010004543381156195...</td>\n",
       "      <td>[-0.0005936203287212333, -0.006037652244061175...</td>\n",
       "      <td>[0.00106851659169822, 0.011069604951075333, 0....</td>\n",
       "      <td>[-0.00035617219723273994, -0.00402625316996714...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CPSC_extra\\Q0013.mat</td>\n",
       "      <td>67</td>\n",
       "      <td>M</td>\n",
       "      <td>[[0.0011872406574424666, 0.011600408225145364,...</td>\n",
       "      <td>[0.0011872406574424666, 0.011600408225145364, ...</td>\n",
       "      <td>[-0.0008310684602097266, -0.008286499449643698...</td>\n",
       "      <td>[-0.002018309117652193, -0.019886907674789057,...</td>\n",
       "      <td>[-0.00011872406574424665, -0.00112442360279126...</td>\n",
       "      <td>[0.0016027748875473299, 0.015684295917095095, ...</td>\n",
       "      <td>[-0.0013653267560588367, -0.01349481074438469,...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CPSC_extra\\Q0017.mat</td>\n",
       "      <td>65</td>\n",
       "      <td>F</td>\n",
       "      <td>[[-0.00053425829584911, -0.006276827886439209,...</td>\n",
       "      <td>[-0.00053425829584911, -0.006276827886439209, ...</td>\n",
       "      <td>[-0.0007123443944654799, -0.008705488701527646...</td>\n",
       "      <td>[-0.00017808609861636997, -0.00242866081508843...</td>\n",
       "      <td>[0.0005936203287212333, 0.007284254934375765, ...</td>\n",
       "      <td>[-0.00017808609861636997, -0.00195376455211144...</td>\n",
       "      <td>[-0.0004748962629769866, -0.005803659134351762...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                filename age gender  \\\n",
       "0   CPSC_extra\\Q0001.mat  53      M   \n",
       "7   CPSC_extra\\Q0010.mat  72      M   \n",
       "9   CPSC_extra\\Q0012.mat  79      F   \n",
       "10  CPSC_extra\\Q0013.mat  67      M   \n",
       "14  CPSC_extra\\Q0017.mat  65      F   \n",
       "\n",
       "                                           ecg_signal  \\\n",
       "0   [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -5.93620328721...   \n",
       "7   [[0.002374481314884933, 0.023794436779011958, ...   \n",
       "9   [[0.0011278786245703433, 0.011542773703162784,...   \n",
       "10  [[0.0011872406574424666, 0.011600408225145364,...   \n",
       "14  [[-0.00053425829584911, -0.006276827886439209,...   \n",
       "\n",
       "                                               Lead I  \\\n",
       "0   [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -5.936203287212...   \n",
       "7   [0.002374481314884933, 0.023794436779011958, 0...   \n",
       "9   [0.0011278786245703433, 0.011542773703162784, ...   \n",
       "10  [0.0011872406574424666, 0.011600408225145364, ...   \n",
       "14  [-0.00053425829584911, -0.006276827886439209, ...   \n",
       "\n",
       "                                              Lead II  \\\n",
       "0   [0.0005936203287212333, 0.006037652244061175, ...   \n",
       "7   [0.00029681016436061664, 0.0028407400234142176...   \n",
       "9   [0.00011872406574424665, 0.0010056995370470159...   \n",
       "10  [-0.0008310684602097266, -0.008286499449643698...   \n",
       "14  [-0.0007123443944654799, -0.008705488701527646...   \n",
       "\n",
       "                                             Lead III  \\\n",
       "0   [0.0005936203287212333, 0.006097014276933299, ...   \n",
       "7   [-0.0020776711505243167, -0.020953696755597745...   \n",
       "9   [-0.0009497925259539732, -0.010004543381156195...   \n",
       "10  [-0.002018309117652193, -0.019886907674789057,...   \n",
       "14  [-0.00017808609861636997, -0.00242866081508843...   \n",
       "\n",
       "                                                  aVR  \\\n",
       "0   [-0.00029681016436061664, -0.00307818815490271...   \n",
       "7   [-0.0013059647231867132, -0.013021641992297241...   \n",
       "9   [-0.0005936203287212333, -0.006037652244061175...   \n",
       "10  [-0.00011872406574424665, -0.00112442360279126...   \n",
       "14  [0.0005936203287212333, 0.007284254934375765, ...   \n",
       "\n",
       "                                                  aVL  \\\n",
       "0   [-0.00029681016436061664, -0.00307818815490271...   \n",
       "7   [0.0021963952162685632, 0.022078120358389002, ...   \n",
       "9   [0.00106851659169822, 0.011069604951075333, 0....   \n",
       "10  [0.0016027748875473299, 0.015684295917095095, ...   \n",
       "14  [-0.00017808609861636997, -0.00195376455211144...   \n",
       "\n",
       "                                                  aVF  ... 427084000  \\\n",
       "0   [0.0006529823615933566, 0.006629545061892868, ...  ...         1   \n",
       "7   [-0.0008904304930818499, -0.009056478366091763...  ...         0   \n",
       "9   [-0.00035617219723273994, -0.00402625316996714...  ...         0   \n",
       "10  [-0.0013653267560588367, -0.01349481074438469,...  ...         0   \n",
       "14  [-0.0004748962629769866, -0.005803659134351762...  ...         0   \n",
       "\n",
       "   427172004 427393009 47665007 59118001 59931005  63593006  698252002  \\\n",
       "0          0         0        0        0        0         0          0   \n",
       "7          1         0        0        0        0         0          0   \n",
       "9          0         0        0        0        0         0          0   \n",
       "10         1         0        0        0        0         0          0   \n",
       "14         0         0        0        0        0         1          0   \n",
       "\n",
       "    713426002  713427006  \n",
       "0           0          0  \n",
       "7           0          0  \n",
       "9           0          0  \n",
       "10          0          0  \n",
       "14          0          0  \n",
       "\n",
       "[5 rows x 39 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xdf = enc.organize()\n",
    "xdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>age</th>\n",
       "      <th>gender</th>\n",
       "      <th>ecg_signal</th>\n",
       "      <th>Lead I</th>\n",
       "      <th>Lead II</th>\n",
       "      <th>Lead III</th>\n",
       "      <th>aVR</th>\n",
       "      <th>aVL</th>\n",
       "      <th>aVF</th>\n",
       "      <th>...</th>\n",
       "      <th>427084000</th>\n",
       "      <th>427172004</th>\n",
       "      <th>427393009</th>\n",
       "      <th>47665007</th>\n",
       "      <th>59118001</th>\n",
       "      <th>59931005</th>\n",
       "      <th>63593006</th>\n",
       "      <th>698252002</th>\n",
       "      <th>713426002</th>\n",
       "      <th>713427006</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CPSC_extra\\Q0001.mat</td>\n",
       "      <td>53</td>\n",
       "      <td>M</td>\n",
       "      <td>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -5.93620328721...</td>\n",
       "      <td>[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -5.936203287212...</td>\n",
       "      <td>[0.0005936203287212333, 0.006037652244061175, ...</td>\n",
       "      <td>[0.0005936203287212333, 0.006097014276933299, ...</td>\n",
       "      <td>[-0.00029681016436061664, -0.00307818815490271...</td>\n",
       "      <td>[-0.00029681016436061664, -0.00307818815490271...</td>\n",
       "      <td>[0.0006529823615933566, 0.006629545061892868, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>CPSC_extra\\Q0010.mat</td>\n",
       "      <td>72</td>\n",
       "      <td>M</td>\n",
       "      <td>[[0.002374481314884933, 0.023794436779011958, ...</td>\n",
       "      <td>[0.002374481314884933, 0.023794436779011958, 0...</td>\n",
       "      <td>[0.00029681016436061664, 0.0028407400234142176...</td>\n",
       "      <td>[-0.0020776711505243167, -0.020953696755597745...</td>\n",
       "      <td>[-0.0013059647231867132, -0.013021641992297241...</td>\n",
       "      <td>[0.0021963952162685632, 0.022078120358389002, ...</td>\n",
       "      <td>[-0.0008904304930818499, -0.009056478366091763...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>CPSC_extra\\Q0012.mat</td>\n",
       "      <td>79</td>\n",
       "      <td>F</td>\n",
       "      <td>[[0.0011278786245703433, 0.011542773703162784,...</td>\n",
       "      <td>[0.0011278786245703433, 0.011542773703162784, ...</td>\n",
       "      <td>[0.00011872406574424665, 0.0010056995370470159...</td>\n",
       "      <td>[-0.0009497925259539732, -0.010004543381156195...</td>\n",
       "      <td>[-0.0005936203287212333, -0.006037652244061175...</td>\n",
       "      <td>[0.00106851659169822, 0.011069604951075333, 0....</td>\n",
       "      <td>[-0.00035617219723273994, -0.00402625316996714...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>CPSC_extra\\Q0013.mat</td>\n",
       "      <td>67</td>\n",
       "      <td>M</td>\n",
       "      <td>[[0.0011872406574424666, 0.011600408225145364,...</td>\n",
       "      <td>[0.0011872406574424666, 0.011600408225145364, ...</td>\n",
       "      <td>[-0.0008310684602097266, -0.008286499449643698...</td>\n",
       "      <td>[-0.002018309117652193, -0.019886907674789057,...</td>\n",
       "      <td>[-0.00011872406574424665, -0.00112442360279126...</td>\n",
       "      <td>[0.0016027748875473299, 0.015684295917095095, ...</td>\n",
       "      <td>[-0.0013653267560588367, -0.01349481074438469,...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>CPSC_extra\\Q0017.mat</td>\n",
       "      <td>65</td>\n",
       "      <td>F</td>\n",
       "      <td>[[-0.00053425829584911, -0.006276827886439209,...</td>\n",
       "      <td>[-0.00053425829584911, -0.006276827886439209, ...</td>\n",
       "      <td>[-0.0007123443944654799, -0.008705488701527646...</td>\n",
       "      <td>[-0.00017808609861636997, -0.00242866081508843...</td>\n",
       "      <td>[0.0005936203287212333, 0.007284254934375765, ...</td>\n",
       "      <td>[-0.00017808609861636997, -0.00195376455211144...</td>\n",
       "      <td>[-0.0004748962629769866, -0.005803659134351762...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3439</th>\n",
       "      <td>CPSC_extra\\Q3568.mat</td>\n",
       "      <td>69</td>\n",
       "      <td>M</td>\n",
       "      <td>[[-0.008844942897946375, -0.08807330579117797,...</td>\n",
       "      <td>[-0.008844942897946375, -0.08807330579117797, ...</td>\n",
       "      <td>[-0.00783578833912028, -0.0780111278880392, -0...</td>\n",
       "      <td>[0.0010091545588260965, 0.010062177903138776, ...</td>\n",
       "      <td>[0.008310684602097267, 0.08274627043069277, 0....</td>\n",
       "      <td>[-0.004927048728386236, -0.049008379814286254,...</td>\n",
       "      <td>[-0.0033836358737110296, -0.033619166550662244...</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3441</th>\n",
       "      <td>CPSC_extra\\Q3570.mat</td>\n",
       "      <td>75</td>\n",
       "      <td>M</td>\n",
       "      <td>[[0.04155342301048633, 0.41533412704101114, 2....</td>\n",
       "      <td>[0.04155342301048633, 0.41533412704101114, 2.0...</td>\n",
       "      <td>[0.06084608369392641, 0.6038407606996232, 2.96...</td>\n",
       "      <td>[0.019292660683440082, 0.18850663365861214, 0....</td>\n",
       "      <td>[-0.051170072335770304, -0.5093211784778373, -...</td>\n",
       "      <td>[0.011100700147087063, 0.11311780028228363, 0....</td>\n",
       "      <td>[0.04006937218868325, 0.39614401616268163, 1.9...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3443</th>\n",
       "      <td>CPSC_extra\\Q3572.mat</td>\n",
       "      <td>66</td>\n",
       "      <td>M</td>\n",
       "      <td>[[0.011516234377191925, 0.12046659978220013, 0...</td>\n",
       "      <td>[0.011516234377191925, 0.12046659978220013, 0....</td>\n",
       "      <td>[-0.0022557572491406865, -0.022848099274837073...</td>\n",
       "      <td>[-0.013771991626332612, -0.1433146990570372, -...</td>\n",
       "      <td>[-0.00463023856402562, -0.0488389312701176, -0...</td>\n",
       "      <td>[0.012644113001762268, 0.13195001145249077, 0....</td>\n",
       "      <td>[-0.008013874437736648, -0.08311108018237318, ...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3444</th>\n",
       "      <td>CPSC_extra\\Q3573.mat</td>\n",
       "      <td>84</td>\n",
       "      <td>M</td>\n",
       "      <td>[[-0.00029681016436061664, -0.0029001020562863...</td>\n",
       "      <td>[-0.00029681016436061664, -0.00290010205628634...</td>\n",
       "      <td>[-0.0013653267560588367, -0.013732258875873185...</td>\n",
       "      <td>[-0.00106851659169822, -0.01077279478671472, -...</td>\n",
       "      <td>[0.0008310684602097266, 0.008345861482515822, ...</td>\n",
       "      <td>[0.00035617219723273994, 0.0036107189398622806...</td>\n",
       "      <td>[-0.0012466026903145896, -0.012548473240209794...</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3446</th>\n",
       "      <td>CPSC_extra\\Q3575.mat</td>\n",
       "      <td>64</td>\n",
       "      <td>M</td>\n",
       "      <td>[[0.0004748962629769866, 0.005328762871374776,...</td>\n",
       "      <td>[0.0004748962629769866, 0.005328762871374776, ...</td>\n",
       "      <td>[-0.00017808609861636997, -0.00141950625626233...</td>\n",
       "      <td>[-0.0006529823615933566, -0.006748269127637115...</td>\n",
       "      <td>[-0.00011872406574424665, -0.00165868189864037...</td>\n",
       "      <td>[0.00053425829584911, 0.005801931623462223, 0....</td>\n",
       "      <td>[-0.0004155342301048633, -0.004083887691949726...</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1278 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  filename age gender  \\\n",
       "0     CPSC_extra\\Q0001.mat  53      M   \n",
       "7     CPSC_extra\\Q0010.mat  72      M   \n",
       "9     CPSC_extra\\Q0012.mat  79      F   \n",
       "10    CPSC_extra\\Q0013.mat  67      M   \n",
       "14    CPSC_extra\\Q0017.mat  65      F   \n",
       "...                    ...  ..    ...   \n",
       "3439  CPSC_extra\\Q3568.mat  69      M   \n",
       "3441  CPSC_extra\\Q3570.mat  75      M   \n",
       "3443  CPSC_extra\\Q3572.mat  66      M   \n",
       "3444  CPSC_extra\\Q3573.mat  84      M   \n",
       "3446  CPSC_extra\\Q3575.mat  64      M   \n",
       "\n",
       "                                             ecg_signal  \\\n",
       "0     [[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -5.93620328721...   \n",
       "7     [[0.002374481314884933, 0.023794436779011958, ...   \n",
       "9     [[0.0011278786245703433, 0.011542773703162784,...   \n",
       "10    [[0.0011872406574424666, 0.011600408225145364,...   \n",
       "14    [[-0.00053425829584911, -0.006276827886439209,...   \n",
       "...                                                 ...   \n",
       "3439  [[-0.008844942897946375, -0.08807330579117797,...   \n",
       "3441  [[0.04155342301048633, 0.41533412704101114, 2....   \n",
       "3443  [[0.011516234377191925, 0.12046659978220013, 0...   \n",
       "3444  [[-0.00029681016436061664, -0.0029001020562863...   \n",
       "3446  [[0.0004748962629769866, 0.005328762871374776,...   \n",
       "\n",
       "                                                 Lead I  \\\n",
       "0     [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -5.936203287212...   \n",
       "7     [0.002374481314884933, 0.023794436779011958, 0...   \n",
       "9     [0.0011278786245703433, 0.011542773703162784, ...   \n",
       "10    [0.0011872406574424666, 0.011600408225145364, ...   \n",
       "14    [-0.00053425829584911, -0.006276827886439209, ...   \n",
       "...                                                 ...   \n",
       "3439  [-0.008844942897946375, -0.08807330579117797, ...   \n",
       "3441  [0.04155342301048633, 0.41533412704101114, 2.0...   \n",
       "3443  [0.011516234377191925, 0.12046659978220013, 0....   \n",
       "3444  [-0.00029681016436061664, -0.00290010205628634...   \n",
       "3446  [0.0004748962629769866, 0.005328762871374776, ...   \n",
       "\n",
       "                                                Lead II  \\\n",
       "0     [0.0005936203287212333, 0.006037652244061175, ...   \n",
       "7     [0.00029681016436061664, 0.0028407400234142176...   \n",
       "9     [0.00011872406574424665, 0.0010056995370470159...   \n",
       "10    [-0.0008310684602097266, -0.008286499449643698...   \n",
       "14    [-0.0007123443944654799, -0.008705488701527646...   \n",
       "...                                                 ...   \n",
       "3439  [-0.00783578833912028, -0.0780111278880392, -0...   \n",
       "3441  [0.06084608369392641, 0.6038407606996232, 2.96...   \n",
       "3443  [-0.0022557572491406865, -0.022848099274837073...   \n",
       "3444  [-0.0013653267560588367, -0.013732258875873185...   \n",
       "3446  [-0.00017808609861636997, -0.00141950625626233...   \n",
       "\n",
       "                                               Lead III  \\\n",
       "0     [0.0005936203287212333, 0.006097014276933299, ...   \n",
       "7     [-0.0020776711505243167, -0.020953696755597745...   \n",
       "9     [-0.0009497925259539732, -0.010004543381156195...   \n",
       "10    [-0.002018309117652193, -0.019886907674789057,...   \n",
       "14    [-0.00017808609861636997, -0.00242866081508843...   \n",
       "...                                                 ...   \n",
       "3439  [0.0010091545588260965, 0.010062177903138776, ...   \n",
       "3441  [0.019292660683440082, 0.18850663365861214, 0....   \n",
       "3443  [-0.013771991626332612, -0.1433146990570372, -...   \n",
       "3444  [-0.00106851659169822, -0.01077279478671472, -...   \n",
       "3446  [-0.0006529823615933566, -0.006748269127637115...   \n",
       "\n",
       "                                                    aVR  \\\n",
       "0     [-0.00029681016436061664, -0.00307818815490271...   \n",
       "7     [-0.0013059647231867132, -0.013021641992297241...   \n",
       "9     [-0.0005936203287212333, -0.006037652244061175...   \n",
       "10    [-0.00011872406574424665, -0.00112442360279126...   \n",
       "14    [0.0005936203287212333, 0.007284254934375765, ...   \n",
       "...                                                 ...   \n",
       "3439  [0.008310684602097267, 0.08274627043069277, 0....   \n",
       "3441  [-0.051170072335770304, -0.5093211784778373, -...   \n",
       "3443  [-0.00463023856402562, -0.0488389312701176, -0...   \n",
       "3444  [0.0008310684602097266, 0.008345861482515822, ...   \n",
       "3446  [-0.00011872406574424665, -0.00165868189864037...   \n",
       "\n",
       "                                                    aVL  \\\n",
       "0     [-0.00029681016436061664, -0.00307818815490271...   \n",
       "7     [0.0021963952162685632, 0.022078120358389002, ...   \n",
       "9     [0.00106851659169822, 0.011069604951075333, 0....   \n",
       "10    [0.0016027748875473299, 0.015684295917095095, ...   \n",
       "14    [-0.00017808609861636997, -0.00195376455211144...   \n",
       "...                                                 ...   \n",
       "3439  [-0.004927048728386236, -0.049008379814286254,...   \n",
       "3441  [0.011100700147087063, 0.11311780028228363, 0....   \n",
       "3443  [0.012644113001762268, 0.13195001145249077, 0....   \n",
       "3444  [0.00035617219723273994, 0.0036107189398622806...   \n",
       "3446  [0.00053425829584911, 0.005801931623462223, 0....   \n",
       "\n",
       "                                                    aVF  ... 427084000  \\\n",
       "0     [0.0006529823615933566, 0.006629545061892868, ...  ...         1   \n",
       "7     [-0.0008904304930818499, -0.009056478366091763...  ...         0   \n",
       "9     [-0.00035617219723273994, -0.00402625316996714...  ...         0   \n",
       "10    [-0.0013653267560588367, -0.01349481074438469,...  ...         0   \n",
       "14    [-0.0004748962629769866, -0.005803659134351762...  ...         0   \n",
       "...                                                 ...  ...       ...   \n",
       "3439  [-0.0033836358737110296, -0.033619166550662244...  ...         1   \n",
       "3441  [0.04006937218868325, 0.39614401616268163, 1.9...  ...         0   \n",
       "3443  [-0.008013874437736648, -0.08311108018237318, ...  ...         0   \n",
       "3444  [-0.0012466026903145896, -0.012548473240209794...  ...         0   \n",
       "3446  [-0.0004155342301048633, -0.004083887691949726...  ...         1   \n",
       "\n",
       "     427172004 427393009 47665007 59118001 59931005  63593006  698252002  \\\n",
       "0            0         0        0        0        0         0          0   \n",
       "7            1         0        0        0        0         0          0   \n",
       "9            0         0        0        0        0         0          0   \n",
       "10           1         0        0        0        0         0          0   \n",
       "14           0         0        0        0        0         1          0   \n",
       "...        ...       ...      ...      ...      ...       ...        ...   \n",
       "3439         0         0        0        0        0         0          0   \n",
       "3441         0         0        0        0        0         0          0   \n",
       "3443         0         0        0        0        0         0          0   \n",
       "3444         0         0        0        0        0         0          0   \n",
       "3446         0         0        0        0        0         0          0   \n",
       "\n",
       "      713426002  713427006  \n",
       "0             0          0  \n",
       "7             0          0  \n",
       "9             0          0  \n",
       "10            0          0  \n",
       "14            0          0  \n",
       "...         ...        ...  \n",
       "3439          0          0  \n",
       "3441          0          0  \n",
       "3443          0          0  \n",
       "3444          0          0  \n",
       "3446          0          0  \n",
       "\n",
       "[1278 rows x 39 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating final csv for input to the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_df = utils.get_extract_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = utils.Extract()\n",
    "for i in range(len(xdf['Lead I'])):\n",
    "    ## Getting a fixed portion of the signal for all records\n",
    "    row = np.array(xdf['Lead I'].iloc[i])[0:4900]\n",
    "    indexes,avg,local,pre,post = ex.feature_extraction(row)\n",
    "    appending = utils.table(indexes,avg,local,pre,post,row)\n",
    "    extract_df = extract_df.append(appending, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_df.index = xdf.index\n",
    "extract_df['Age'] = xdf['age'].astype(int)\n",
    "extract_df['Gender'] = xdf['gender']\n",
    "extract_df['Bradycardia'] = xdf['426627000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender = {'M': 1,'F': 0}\n",
    "extract_df['Gender']= [gender[item] for item in extract_df['Gender']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column 0</th>\n",
       "      <th>Column 1</th>\n",
       "      <th>Column 2</th>\n",
       "      <th>Column 3</th>\n",
       "      <th>Column 4</th>\n",
       "      <th>Column 5</th>\n",
       "      <th>Column 6</th>\n",
       "      <th>Column 7</th>\n",
       "      <th>Column 8</th>\n",
       "      <th>Column 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Column 47</th>\n",
       "      <th>Column 48</th>\n",
       "      <th>Column 49</th>\n",
       "      <th>Column 50</th>\n",
       "      <th>Column 51</th>\n",
       "      <th>Column 52</th>\n",
       "      <th>Column 53</th>\n",
       "      <th>Age</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Bradycardia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37.802565</td>\n",
       "      <td>15.150810</td>\n",
       "      <td>2.260090</td>\n",
       "      <td>-7.430376</td>\n",
       "      <td>-9.556524</td>\n",
       "      <td>-13.903191</td>\n",
       "      <td>-15.424708</td>\n",
       "      <td>-11.692536</td>\n",
       "      <td>-14.367256</td>\n",
       "      <td>-15.850709</td>\n",
       "      <td>...</td>\n",
       "      <td>65.667756</td>\n",
       "      <td>68.622270</td>\n",
       "      <td>64.069238</td>\n",
       "      <td>292.187500</td>\n",
       "      <td>291.0</td>\n",
       "      <td>289.0</td>\n",
       "      <td>297.0</td>\n",
       "      <td>53</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>32.557329</td>\n",
       "      <td>36.348807</td>\n",
       "      <td>36.543610</td>\n",
       "      <td>31.775924</td>\n",
       "      <td>28.605957</td>\n",
       "      <td>28.673300</td>\n",
       "      <td>32.864237</td>\n",
       "      <td>39.236214</td>\n",
       "      <td>44.040396</td>\n",
       "      <td>40.360254</td>\n",
       "      <td>...</td>\n",
       "      <td>1.841055</td>\n",
       "      <td>2.904830</td>\n",
       "      <td>-0.274903</td>\n",
       "      <td>151.120690</td>\n",
       "      <td>184.0</td>\n",
       "      <td>213.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>24.234741</td>\n",
       "      <td>30.161992</td>\n",
       "      <td>26.665471</td>\n",
       "      <td>27.675008</td>\n",
       "      <td>28.729342</td>\n",
       "      <td>25.548108</td>\n",
       "      <td>27.649770</td>\n",
       "      <td>24.498895</td>\n",
       "      <td>22.428535</td>\n",
       "      <td>22.276434</td>\n",
       "      <td>...</td>\n",
       "      <td>6.178079</td>\n",
       "      <td>15.265456</td>\n",
       "      <td>19.466162</td>\n",
       "      <td>504.611111</td>\n",
       "      <td>489.0</td>\n",
       "      <td>515.0</td>\n",
       "      <td>506.0</td>\n",
       "      <td>79</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-1.359098</td>\n",
       "      <td>-3.130226</td>\n",
       "      <td>-32.264112</td>\n",
       "      <td>6.973123</td>\n",
       "      <td>-9.746203</td>\n",
       "      <td>-16.123716</td>\n",
       "      <td>-32.708909</td>\n",
       "      <td>-16.748308</td>\n",
       "      <td>-24.308965</td>\n",
       "      <td>-36.751383</td>\n",
       "      <td>...</td>\n",
       "      <td>-51.418699</td>\n",
       "      <td>-63.409432</td>\n",
       "      <td>-55.863976</td>\n",
       "      <td>437.500000</td>\n",
       "      <td>166.0</td>\n",
       "      <td>461.0</td>\n",
       "      <td>463.0</td>\n",
       "      <td>67</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-73.632095</td>\n",
       "      <td>-55.800372</td>\n",
       "      <td>-79.456874</td>\n",
       "      <td>40.047609</td>\n",
       "      <td>466.682850</td>\n",
       "      <td>749.100638</td>\n",
       "      <td>552.074413</td>\n",
       "      <td>-156.881256</td>\n",
       "      <td>-172.601357</td>\n",
       "      <td>-121.936011</td>\n",
       "      <td>...</td>\n",
       "      <td>171.228402</td>\n",
       "      <td>-13.782800</td>\n",
       "      <td>-55.603575</td>\n",
       "      <td>396.625000</td>\n",
       "      <td>402.0</td>\n",
       "      <td>399.0</td>\n",
       "      <td>826.0</td>\n",
       "      <td>65</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3439</th>\n",
       "      <td>-43.980290</td>\n",
       "      <td>-37.267718</td>\n",
       "      <td>-42.805083</td>\n",
       "      <td>-48.126681</td>\n",
       "      <td>-49.715928</td>\n",
       "      <td>-43.449656</td>\n",
       "      <td>-30.222119</td>\n",
       "      <td>-21.441389</td>\n",
       "      <td>-10.531624</td>\n",
       "      <td>-10.474056</td>\n",
       "      <td>...</td>\n",
       "      <td>-43.659580</td>\n",
       "      <td>-48.390178</td>\n",
       "      <td>-50.256107</td>\n",
       "      <td>353.625000</td>\n",
       "      <td>313.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>331.0</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3441</th>\n",
       "      <td>-51.565174</td>\n",
       "      <td>-57.058346</td>\n",
       "      <td>-42.200178</td>\n",
       "      <td>-49.755793</td>\n",
       "      <td>-61.794172</td>\n",
       "      <td>-47.085031</td>\n",
       "      <td>-49.205402</td>\n",
       "      <td>-43.990137</td>\n",
       "      <td>-37.367068</td>\n",
       "      <td>-25.760764</td>\n",
       "      <td>...</td>\n",
       "      <td>-48.277533</td>\n",
       "      <td>-51.722807</td>\n",
       "      <td>-55.758169</td>\n",
       "      <td>353.653846</td>\n",
       "      <td>354.0</td>\n",
       "      <td>352.0</td>\n",
       "      <td>354.0</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3443</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>66</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3444</th>\n",
       "      <td>-15.918028</td>\n",
       "      <td>-10.324103</td>\n",
       "      <td>-10.413024</td>\n",
       "      <td>-9.365415</td>\n",
       "      <td>-6.365869</td>\n",
       "      <td>-9.311673</td>\n",
       "      <td>-2.250115</td>\n",
       "      <td>7.065951</td>\n",
       "      <td>10.463495</td>\n",
       "      <td>31.103461</td>\n",
       "      <td>...</td>\n",
       "      <td>-29.614571</td>\n",
       "      <td>0.224193</td>\n",
       "      <td>-14.691636</td>\n",
       "      <td>371.035714</td>\n",
       "      <td>371.0</td>\n",
       "      <td>397.0</td>\n",
       "      <td>363.0</td>\n",
       "      <td>84</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3446</th>\n",
       "      <td>-42.119378</td>\n",
       "      <td>-27.736395</td>\n",
       "      <td>-35.836348</td>\n",
       "      <td>-37.405080</td>\n",
       "      <td>-53.473270</td>\n",
       "      <td>-61.771250</td>\n",
       "      <td>-54.638488</td>\n",
       "      <td>-53.935737</td>\n",
       "      <td>-46.094890</td>\n",
       "      <td>-21.625240</td>\n",
       "      <td>...</td>\n",
       "      <td>18.358394</td>\n",
       "      <td>-20.478930</td>\n",
       "      <td>-37.650591</td>\n",
       "      <td>281.906250</td>\n",
       "      <td>280.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>279.0</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1278 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Column 0   Column 1   Column 2   Column 3    Column 4    Column 5  \\\n",
       "0     37.802565  15.150810   2.260090  -7.430376   -9.556524  -13.903191   \n",
       "7     32.557329  36.348807  36.543610  31.775924   28.605957   28.673300   \n",
       "9     24.234741  30.161992  26.665471  27.675008   28.729342   25.548108   \n",
       "10    -1.359098  -3.130226 -32.264112   6.973123   -9.746203  -16.123716   \n",
       "14   -73.632095 -55.800372 -79.456874  40.047609  466.682850  749.100638   \n",
       "...         ...        ...        ...        ...         ...         ...   \n",
       "3439 -43.980290 -37.267718 -42.805083 -48.126681  -49.715928  -43.449656   \n",
       "3441 -51.565174 -57.058346 -42.200178 -49.755793  -61.794172  -47.085031   \n",
       "3443   0.000000   0.000000   0.000000   0.000000    0.000000    0.000000   \n",
       "3444 -15.918028 -10.324103 -10.413024  -9.365415   -6.365869   -9.311673   \n",
       "3446 -42.119378 -27.736395 -35.836348 -37.405080  -53.473270  -61.771250   \n",
       "\n",
       "        Column 6    Column 7    Column 8    Column 9  ...   Column 47  \\\n",
       "0     -15.424708  -11.692536  -14.367256  -15.850709  ...   65.667756   \n",
       "7      32.864237   39.236214   44.040396   40.360254  ...    1.841055   \n",
       "9      27.649770   24.498895   22.428535   22.276434  ...    6.178079   \n",
       "10    -32.708909  -16.748308  -24.308965  -36.751383  ...  -51.418699   \n",
       "14    552.074413 -156.881256 -172.601357 -121.936011  ...  171.228402   \n",
       "...          ...         ...         ...         ...  ...         ...   \n",
       "3439  -30.222119  -21.441389  -10.531624  -10.474056  ...  -43.659580   \n",
       "3441  -49.205402  -43.990137  -37.367068  -25.760764  ...  -48.277533   \n",
       "3443    0.000000    0.000000    0.000000    0.000000  ...    0.000000   \n",
       "3444   -2.250115    7.065951   10.463495   31.103461  ...  -29.614571   \n",
       "3446  -54.638488  -53.935737  -46.094890  -21.625240  ...   18.358394   \n",
       "\n",
       "      Column 48  Column 49   Column 50  Column 51  Column 52  Column 53  Age  \\\n",
       "0     68.622270  64.069238  292.187500      291.0      289.0      297.0   53   \n",
       "7      2.904830  -0.274903  151.120690      184.0      213.0      109.0   72   \n",
       "9     15.265456  19.466162  504.611111      489.0      515.0      506.0   79   \n",
       "10   -63.409432 -55.863976  437.500000      166.0      461.0      463.0   67   \n",
       "14   -13.782800 -55.603575  396.625000      402.0      399.0      826.0   65   \n",
       "...         ...        ...         ...        ...        ...        ...  ...   \n",
       "3439 -48.390178 -50.256107  353.625000      313.0      329.0      331.0   69   \n",
       "3441 -51.722807 -55.758169  353.653846      354.0      352.0      354.0   75   \n",
       "3443   0.000000   0.000000    0.000000        0.0        0.0        0.0   66   \n",
       "3444   0.224193 -14.691636  371.035714      371.0      397.0      363.0   84   \n",
       "3446 -20.478930 -37.650591  281.906250      280.0      279.0      279.0   64   \n",
       "\n",
       "      Gender  Bradycardia  \n",
       "0          1            0  \n",
       "7          1            0  \n",
       "9          0            1  \n",
       "10         1            0  \n",
       "14         0            0  \n",
       "...      ...          ...  \n",
       "3439       1            0  \n",
       "3441       1            0  \n",
       "3443       1            1  \n",
       "3444       1            0  \n",
       "3446       1            0  \n",
       "\n",
       "[1278 rows x 57 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = extract_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['figure.figsize'] = (12, 10)\n",
    "colors = plt.rcParams['axes.prop_cycle'].by_key()['color']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# neg, pos = np.bincount(X['Bradycardia'])\n",
    "# total = neg + pos\n",
    "# print('Examples:\\n    Total: {}\\n    Positive: {} ({:.2f}% of total)\\n'.format(\n",
    "#     total, pos, 100 * pos / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_bias = np.log(1)\n",
    "# initial_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a utility from sklearn to split and shuffle your dataset.\n",
    "train_df, test_df = train_test_split(X, test_size=0.2, stratify = X['Bradycardia'])\n",
    "train_df, val_df = train_test_split(train_df, test_size=0.2, stratify = train_df['Bradycardia'])\n",
    "\n",
    "\n",
    "y = extract_df.Bradycardia\n",
    "X = extract_df.drop(columns = ['Bradycardia'])\n",
    "\n",
    "oversample = SMOTE()\n",
    "train_df, train_labels = oversample.fit_resample(X, y)\n",
    "\n",
    "train_df['Bradycardia'] = train_labels\n",
    "\n",
    "# Form np arrays of labels and features.\n",
    "train_labels = np.array(train_df.pop('Bradycardia'))\n",
    "bool_train_labels = train_labels != 0\n",
    "val_labels = np.array(val_df.pop('Bradycardia'))\n",
    "test_labels = np.array(test_df.pop('Bradycardia'))\n",
    "\n",
    "train_features = np.array(train_df)\n",
    "val_features = np.array(val_df)\n",
    "test_features = np.array(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training labels shape: (2014,)\n",
      "Validation labels shape: (205,)\n",
      "Test labels shape: (256,)\n",
      "Training features shape: (2014, 56)\n",
      "Validation features shape: (205, 56)\n",
      "Test features shape: (256, 56)\n"
     ]
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "#scaler = MinMaxScaler()\n",
    "train_features = scaler.fit_transform(train_features)\n",
    "\n",
    "val_features = scaler.transform(val_features)\n",
    "test_features = scaler.transform(test_features)\n",
    "\n",
    "train_features = np.clip(train_features, -5, 5)\n",
    "val_features = np.clip(val_features, -5, 5)\n",
    "test_features = np.clip(test_features, -5, 5)\n",
    "\n",
    "\n",
    "print('Training labels shape:', train_labels.shape)\n",
    "print('Validation labels shape:', val_labels.shape)\n",
    "print('Test labels shape:', test_labels.shape)\n",
    "\n",
    "print('Training features shape:', train_features.shape)\n",
    "print('Validation features shape:', val_features.shape)\n",
    "print('Test features shape:', test_features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cm(labels, predictions, p=0.5):\n",
    "  cm = confusion_matrix(labels, predictions > p)\n",
    "  plt.figure(figsize=(5,5))\n",
    "  sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "  plt.title('Confusion matrix @{:.2f}'.format(p))\n",
    "  plt.ylabel('Actual label')\n",
    "  plt.xlabel('Predicted label')\n",
    "\n",
    "  print('Bradycardia Detected (True Negatives): ', cm[0][0])\n",
    "  print('Bradycardia Incorrectly Detected (False Positives): ', cm[0][1])\n",
    "  print('False Alarm on detection (False Negatives): ', cm[1][0])\n",
    "  print('Not Bradycardia detected (True Positives): ', cm[1][1])\n",
    "  print('Total No Disease Diagnosis: ', np.sum(cm[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "METRICS = [\n",
    "      keras.metrics.TruePositives(name='tp'),\n",
    "      #keras.metrics.FalsePositives(name='fp'),\n",
    "      #keras.metrics.TrueNegatives(name='tn'),\n",
    "      keras.metrics.FalseNegatives(name='fn'), \n",
    "      keras.metrics.BinaryAccuracy(name='accuracy'),\n",
    "      #keras.metrics.Precision(name='precision'),\n",
    "      #keras.metrics.Recall(name='recall'),\n",
    "      keras.metrics.AUC(name='auc'),\n",
    "      keras.metrics.AUC(name='prc', curve='PR'), # precision-recall curve\n",
    "]\n",
    "\n",
    "def make_model(metrics=METRICS, output_bias=None):\n",
    "  if output_bias is not None:\n",
    "    output_bias = tf.keras.initializers.Constant(output_bias)\n",
    "  model = keras.Sequential([\n",
    "      keras.layers.Dense(16, activation='relu',input_shape=(train_features.shape[-1],)),\n",
    "      keras.layers.Dense(32, activation = 'tanh'),\n",
    "      keras.layers.Dense(64, activation = 'tanh'),\n",
    "      keras.layers.Dropout(0.5),\n",
    "      keras.layers.Dense(1, activation='sigmoid',\n",
    "                         bias_initializer=output_bias),\n",
    "  ])\n",
    "\n",
    "  model.compile(\n",
    "      optimizer=keras.optimizers.Adam(lr=1e-3),\n",
    "      loss=keras.losses.BinaryCrossentropy(),\n",
    "      metrics=metrics)\n",
    "\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "BATCH_SIZE = 2048\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_prc', \n",
    "    verbose=1,\n",
    "    patience=10,\n",
    "    mode='max',\n",
    "    restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 16)                912       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 32)                544       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 64)                2112      \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 3,633\n",
      "Trainable params: 3,633\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = make_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7561\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(train_features, train_labels, batch_size=BATCH_SIZE, verbose=0)\n",
    "print(\"Loss: {:0.4f}\".format(results[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicting based on class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Scaling by total/2 helps keep the loss to a similar magnitude.\n",
    "# # The sum of the weights of all examples stays the same.\n",
    "# weight_for_0 = (1 / neg) * (total / 2.0)\n",
    "# weight_for_1 = (1 / pos) * (total / 2.0)\n",
    "\n",
    "# class_weight = {0: weight_for_0, 1: weight_for_1}\n",
    "\n",
    "# print('Weight for class 0: {:.2f}'.format(weight_for_0))\n",
    "# print('Weight for class 1: {:.2f}'.format(weight_for_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1/1 [==============================] - 1s 756ms/step - loss: 0.8354 - tp: 21.0000 - fn: 1993.0000 - accuracy: 0.4695 - auc: 0.5000 - prc: 0.4721 - val_loss: 0.5235 - val_tp: 0.0000e+00 - val_fn: 44.0000 - val_accuracy: 0.7805 - val_auc: 0.6064 - val_prc: 0.2408\n",
      "Epoch 2/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.8038 - tp: 28.0000 - fn: 979.0000 - accuracy: 0.4861 - auc: 0.5621 - prc: 0.5144 - val_loss: 0.5270 - val_tp: 0.0000e+00 - val_fn: 44.0000 - val_accuracy: 0.7707 - val_auc: 0.6175 - val_prc: 0.2519\n",
      "Epoch 3/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.7941 - tp: 45.0000 - fn: 962.0000 - accuracy: 0.4801 - auc: 0.5545 - prc: 0.5067 - val_loss: 0.5315 - val_tp: 0.0000e+00 - val_fn: 44.0000 - val_accuracy: 0.7610 - val_auc: 0.6295 - val_prc: 0.2667\n",
      "Epoch 4/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7694 - tp: 76.0000 - fn: 931.0000 - accuracy: 0.4926 - auc: 0.5841 - prc: 0.5392 - val_loss: 0.5371 - val_tp: 0.0000e+00 - val_fn: 44.0000 - val_accuracy: 0.7610 - val_auc: 0.6432 - val_prc: 0.2834\n",
      "Epoch 5/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.7607 - tp: 142.0000 - fn: 865.0000 - accuracy: 0.5060 - auc: 0.5696 - prc: 0.5250 - val_loss: 0.5434 - val_tp: 1.0000 - val_fn: 43.0000 - val_accuracy: 0.7512 - val_auc: 0.6584 - val_prc: 0.3030\n",
      "Epoch 6/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.7381 - tp: 192.0000 - fn: 815.0000 - accuracy: 0.5233 - auc: 0.5956 - prc: 0.5500 - val_loss: 0.5502 - val_tp: 5.0000 - val_fn: 39.0000 - val_accuracy: 0.7317 - val_auc: 0.6688 - val_prc: 0.3194\n",
      "Epoch 7/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.7189 - tp: 283.0000 - fn: 724.0000 - accuracy: 0.5526 - auc: 0.6119 - prc: 0.5714 - val_loss: 0.5572 - val_tp: 17.0000 - val_fn: 27.0000 - val_accuracy: 0.7659 - val_auc: 0.6762 - val_prc: 0.3312\n",
      "Epoch 8/100\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.7143 - tp: 367.0000 - fn: 640.0000 - accuracy: 0.5760 - auc: 0.6139 - prc: 0.5789 - val_loss: 0.5639 - val_tp: 23.0000 - val_fn: 21.0000 - val_accuracy: 0.7561 - val_auc: 0.6853 - val_prc: 0.3452\n",
      "Epoch 9/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.7033 - tp: 428.0000 - fn: 579.0000 - accuracy: 0.5929 - auc: 0.6256 - prc: 0.5875 - val_loss: 0.5702 - val_tp: 29.0000 - val_fn: 15.0000 - val_accuracy: 0.7707 - val_auc: 0.6894 - val_prc: 0.3514\n",
      "Epoch 10/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.6884 - tp: 489.0000 - fn: 518.0000 - accuracy: 0.6207 - auc: 0.6427 - prc: 0.6072 - val_loss: 0.5759 - val_tp: 30.0000 - val_fn: 14.0000 - val_accuracy: 0.7707 - val_auc: 0.6962 - val_prc: 0.3580\n",
      "Epoch 11/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6786 - tp: 502.0000 - fn: 505.0000 - accuracy: 0.6172 - auc: 0.6465 - prc: 0.6233 - val_loss: 0.5808 - val_tp: 30.0000 - val_fn: 14.0000 - val_accuracy: 0.7610 - val_auc: 0.7019 - val_prc: 0.3638\n",
      "Epoch 12/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6747 - tp: 544.0000 - fn: 463.0000 - accuracy: 0.6276 - auc: 0.6568 - prc: 0.6164 - val_loss: 0.5844 - val_tp: 30.0000 - val_fn: 14.0000 - val_accuracy: 0.7659 - val_auc: 0.7081 - val_prc: 0.3669\n",
      "Epoch 13/100\n",
      "1/1 [==============================] - 0s 32ms/step - loss: 0.6647 - tp: 586.0000 - fn: 421.0000 - accuracy: 0.6475 - auc: 0.6701 - prc: 0.6416 - val_loss: 0.5871 - val_tp: 30.0000 - val_fn: 14.0000 - val_accuracy: 0.7512 - val_auc: 0.7153 - val_prc: 0.3727\n",
      "Epoch 14/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.6606 - tp: 603.0000 - fn: 404.0000 - accuracy: 0.6500 - auc: 0.6719 - prc: 0.6399 - val_loss: 0.5884 - val_tp: 30.0000 - val_fn: 14.0000 - val_accuracy: 0.7415 - val_auc: 0.7223 - val_prc: 0.3769\n",
      "Epoch 15/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.6478 - tp: 627.0000 - fn: 380.0000 - accuracy: 0.6708 - auc: 0.6893 - prc: 0.6547 - val_loss: 0.5886 - val_tp: 30.0000 - val_fn: 14.0000 - val_accuracy: 0.7415 - val_auc: 0.7274 - val_prc: 0.3799\n",
      "Epoch 16/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6518 - tp: 634.0000 - fn: 373.0000 - accuracy: 0.6663 - auc: 0.6874 - prc: 0.6545 - val_loss: 0.5875 - val_tp: 30.0000 - val_fn: 14.0000 - val_accuracy: 0.7415 - val_auc: 0.7360 - val_prc: 0.3856\n",
      "Epoch 17/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6332 - tp: 648.0000 - fn: 359.0000 - accuracy: 0.6723 - auc: 0.7101 - prc: 0.6848 - val_loss: 0.5852 - val_tp: 30.0000 - val_fn: 14.0000 - val_accuracy: 0.7366 - val_auc: 0.7410 - val_prc: 0.3892\n",
      "Epoch 18/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6359 - tp: 645.0000 - fn: 362.0000 - accuracy: 0.6728 - auc: 0.7053 - prc: 0.6691 - val_loss: 0.5820 - val_tp: 30.0000 - val_fn: 14.0000 - val_accuracy: 0.7366 - val_auc: 0.7491 - val_prc: 0.3935\n",
      "Epoch 19/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6284 - tp: 645.0000 - fn: 362.0000 - accuracy: 0.6718 - auc: 0.7153 - prc: 0.6843 - val_loss: 0.5778 - val_tp: 30.0000 - val_fn: 14.0000 - val_accuracy: 0.7463 - val_auc: 0.7573 - val_prc: 0.3983\n",
      "Epoch 20/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6300 - tp: 648.0000 - fn: 359.0000 - accuracy: 0.6768 - auc: 0.7154 - prc: 0.6771 - val_loss: 0.5729 - val_tp: 30.0000 - val_fn: 14.0000 - val_accuracy: 0.7415 - val_auc: 0.7618 - val_prc: 0.4020\n",
      "Epoch 21/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6139 - tp: 653.0000 - fn: 354.0000 - accuracy: 0.6867 - auc: 0.7320 - prc: 0.6925 - val_loss: 0.5674 - val_tp: 30.0000 - val_fn: 14.0000 - val_accuracy: 0.7512 - val_auc: 0.7679 - val_prc: 0.4050\n",
      "Epoch 22/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.6130 - tp: 672.0000 - fn: 335.0000 - accuracy: 0.6877 - auc: 0.7316 - prc: 0.7050 - val_loss: 0.5613 - val_tp: 30.0000 - val_fn: 14.0000 - val_accuracy: 0.7561 - val_auc: 0.7751 - val_prc: 0.4103\n",
      "Epoch 23/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.6053 - tp: 656.0000 - fn: 351.0000 - accuracy: 0.6927 - auc: 0.7393 - prc: 0.7086 - val_loss: 0.5550 - val_tp: 30.0000 - val_fn: 14.0000 - val_accuracy: 0.7512 - val_auc: 0.7817 - val_prc: 0.4165\n",
      "Epoch 24/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.6041 - tp: 666.0000 - fn: 341.0000 - accuracy: 0.6956 - auc: 0.7408 - prc: 0.7130 - val_loss: 0.5485 - val_tp: 30.0000 - val_fn: 14.0000 - val_accuracy: 0.7561 - val_auc: 0.7851 - val_prc: 0.4187\n",
      "Epoch 25/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5848 - tp: 673.0000 - fn: 334.0000 - accuracy: 0.7100 - auc: 0.7608 - prc: 0.7388 - val_loss: 0.5420 - val_tp: 31.0000 - val_fn: 13.0000 - val_accuracy: 0.7659 - val_auc: 0.7902 - val_prc: 0.4243\n",
      "Epoch 26/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5940 - tp: 658.0000 - fn: 349.0000 - accuracy: 0.7001 - auc: 0.7547 - prc: 0.7119 - val_loss: 0.5357 - val_tp: 31.0000 - val_fn: 13.0000 - val_accuracy: 0.7659 - val_auc: 0.7960 - val_prc: 0.4299\n",
      "Epoch 27/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5862 - tp: 670.0000 - fn: 337.0000 - accuracy: 0.7100 - auc: 0.7632 - prc: 0.7160 - val_loss: 0.5295 - val_tp: 32.0000 - val_fn: 12.0000 - val_accuracy: 0.7707 - val_auc: 0.8016 - val_prc: 0.4351\n",
      "Epoch 28/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5863 - tp: 664.0000 - fn: 343.0000 - accuracy: 0.7011 - auc: 0.7616 - prc: 0.7269 - val_loss: 0.5235 - val_tp: 32.0000 - val_fn: 12.0000 - val_accuracy: 0.7756 - val_auc: 0.8070 - val_prc: 0.4390\n",
      "Epoch 29/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5789 - tp: 662.0000 - fn: 345.0000 - accuracy: 0.7135 - auc: 0.7706 - prc: 0.7267 - val_loss: 0.5180 - val_tp: 32.0000 - val_fn: 12.0000 - val_accuracy: 0.7756 - val_auc: 0.8111 - val_prc: 0.4420\n",
      "Epoch 30/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5765 - tp: 667.0000 - fn: 340.0000 - accuracy: 0.7090 - auc: 0.7725 - prc: 0.7337 - val_loss: 0.5130 - val_tp: 32.0000 - val_fn: 12.0000 - val_accuracy: 0.7805 - val_auc: 0.8149 - val_prc: 0.4464\n",
      "Epoch 31/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5697 - tp: 661.0000 - fn: 346.0000 - accuracy: 0.7095 - auc: 0.7797 - prc: 0.7305 - val_loss: 0.5084 - val_tp: 32.0000 - val_fn: 12.0000 - val_accuracy: 0.7805 - val_auc: 0.8180 - val_prc: 0.4510\n",
      "Epoch 32/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5620 - tp: 677.0000 - fn: 330.0000 - accuracy: 0.7200 - auc: 0.7871 - prc: 0.7489 - val_loss: 0.5044 - val_tp: 32.0000 - val_fn: 12.0000 - val_accuracy: 0.7805 - val_auc: 0.8214 - val_prc: 0.4549\n",
      "Epoch 33/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5595 - tp: 678.0000 - fn: 329.0000 - accuracy: 0.7239 - auc: 0.7896 - prc: 0.7381 - val_loss: 0.5009 - val_tp: 32.0000 - val_fn: 12.0000 - val_accuracy: 0.7902 - val_auc: 0.8239 - val_prc: 0.4590\n",
      "Epoch 34/100\n",
      "1/1 [==============================] - 0s 29ms/step - loss: 0.5514 - tp: 686.0000 - fn: 321.0000 - accuracy: 0.7249 - auc: 0.7983 - prc: 0.7600 - val_loss: 0.4980 - val_tp: 32.0000 - val_fn: 12.0000 - val_accuracy: 0.7854 - val_auc: 0.8262 - val_prc: 0.4622\n",
      "Epoch 35/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.5518 - tp: 678.0000 - fn: 329.0000 - accuracy: 0.7229 - auc: 0.7957 - prc: 0.7592 - val_loss: 0.4958 - val_tp: 32.0000 - val_fn: 12.0000 - val_accuracy: 0.7854 - val_auc: 0.8291 - val_prc: 0.4667\n",
      "Epoch 36/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5359 - tp: 693.0000 - fn: 314.0000 - accuracy: 0.7344 - auc: 0.8092 - prc: 0.7760 - val_loss: 0.4941 - val_tp: 33.0000 - val_fn: 11.0000 - val_accuracy: 0.7854 - val_auc: 0.8317 - val_prc: 0.4691\n",
      "Epoch 37/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.5510 - tp: 701.0000 - fn: 306.0000 - accuracy: 0.7309 - auc: 0.7971 - prc: 0.7449 - val_loss: 0.4930 - val_tp: 33.0000 - val_fn: 11.0000 - val_accuracy: 0.7854 - val_auc: 0.8321 - val_prc: 0.4688\n",
      "Epoch 38/100\n",
      "1/1 [==============================] - 0s 31ms/step - loss: 0.5256 - tp: 714.0000 - fn: 293.0000 - accuracy: 0.7478 - auc: 0.8173 - prc: 0.7792 - val_loss: 0.4922 - val_tp: 33.0000 - val_fn: 11.0000 - val_accuracy: 0.7756 - val_auc: 0.8343 - val_prc: 0.4735\n",
      "Epoch 39/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.5298 - tp: 714.0000 - fn: 293.0000 - accuracy: 0.7463 - auc: 0.8161 - prc: 0.7677 - val_loss: 0.4918 - val_tp: 34.0000 - val_fn: 10.0000 - val_accuracy: 0.7756 - val_auc: 0.8360 - val_prc: 0.4759\n",
      "Epoch 40/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5225 - tp: 724.0000 - fn: 283.0000 - accuracy: 0.7463 - auc: 0.8206 - prc: 0.7695 - val_loss: 0.4916 - val_tp: 34.0000 - val_fn: 10.0000 - val_accuracy: 0.7756 - val_auc: 0.8360 - val_prc: 0.4763\n",
      "Epoch 41/100\n",
      "1/1 [==============================] - 0s 30ms/step - loss: 0.5214 - tp: 724.0000 - fn: 283.0000 - accuracy: 0.7453 - auc: 0.8210 - prc: 0.7751 - val_loss: 0.4914 - val_tp: 35.0000 - val_fn: 9.0000 - val_accuracy: 0.7854 - val_auc: 0.8368 - val_prc: 0.4765\n",
      "Epoch 42/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.5222 - tp: 738.0000 - fn: 269.0000 - accuracy: 0.7473 - auc: 0.8205 - prc: 0.7747 - val_loss: 0.4911 - val_tp: 36.0000 - val_fn: 8.0000 - val_accuracy: 0.7902 - val_auc: 0.8381 - val_prc: 0.4789\n",
      "Epoch 43/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5122 - tp: 760.0000 - fn: 247.0000 - accuracy: 0.7567 - auc: 0.8274 - prc: 0.7772 - val_loss: 0.4904 - val_tp: 36.0000 - val_fn: 8.0000 - val_accuracy: 0.7902 - val_auc: 0.8406 - val_prc: 0.4850\n",
      "Epoch 44/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.5054 - tp: 771.0000 - fn: 236.0000 - accuracy: 0.7646 - auc: 0.8321 - prc: 0.7889 - val_loss: 0.4893 - val_tp: 36.0000 - val_fn: 8.0000 - val_accuracy: 0.7805 - val_auc: 0.8419 - val_prc: 0.4875\n",
      "Epoch 45/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.4983 - tp: 776.0000 - fn: 231.0000 - accuracy: 0.7661 - auc: 0.8375 - prc: 0.7936 - val_loss: 0.4882 - val_tp: 37.0000 - val_fn: 7.0000 - val_accuracy: 0.7854 - val_auc: 0.8442 - val_prc: 0.4919\n",
      "Epoch 46/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4975 - tp: 776.0000 - fn: 231.0000 - accuracy: 0.7676 - auc: 0.8372 - prc: 0.7847 - val_loss: 0.4864 - val_tp: 37.0000 - val_fn: 7.0000 - val_accuracy: 0.7805 - val_auc: 0.8466 - val_prc: 0.4964\n",
      "Epoch 47/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4950 - tp: 794.0000 - fn: 213.0000 - accuracy: 0.7731 - auc: 0.8394 - prc: 0.7873 - val_loss: 0.4840 - val_tp: 37.0000 - val_fn: 7.0000 - val_accuracy: 0.7805 - val_auc: 0.8484 - val_prc: 0.5013\n",
      "Epoch 48/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4854 - tp: 791.0000 - fn: 216.0000 - accuracy: 0.7711 - auc: 0.8466 - prc: 0.7986 - val_loss: 0.4811 - val_tp: 37.0000 - val_fn: 7.0000 - val_accuracy: 0.7854 - val_auc: 0.8497 - val_prc: 0.5018\n",
      "Epoch 49/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4823 - tp: 812.0000 - fn: 195.0000 - accuracy: 0.7835 - auc: 0.8464 - prc: 0.8010 - val_loss: 0.4778 - val_tp: 36.0000 - val_fn: 8.0000 - val_accuracy: 0.7805 - val_auc: 0.8515 - val_prc: 0.5067\n",
      "Epoch 50/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4781 - tp: 804.0000 - fn: 203.0000 - accuracy: 0.7845 - auc: 0.8504 - prc: 0.8074 - val_loss: 0.4741 - val_tp: 36.0000 - val_fn: 8.0000 - val_accuracy: 0.7756 - val_auc: 0.8539 - val_prc: 0.5138\n",
      "Epoch 51/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4713 - tp: 816.0000 - fn: 191.0000 - accuracy: 0.7880 - auc: 0.8544 - prc: 0.8006 - val_loss: 0.4702 - val_tp: 36.0000 - val_fn: 8.0000 - val_accuracy: 0.7756 - val_auc: 0.8556 - val_prc: 0.5179\n",
      "Epoch 52/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4710 - tp: 817.0000 - fn: 190.0000 - accuracy: 0.7929 - auc: 0.8557 - prc: 0.8029 - val_loss: 0.4662 - val_tp: 37.0000 - val_fn: 7.0000 - val_accuracy: 0.7854 - val_auc: 0.8583 - val_prc: 0.5220\n",
      "Epoch 53/100\n",
      "1/1 [==============================] - 0s 26ms/step - loss: 0.4615 - tp: 838.0000 - fn: 169.0000 - accuracy: 0.7999 - auc: 0.8607 - prc: 0.8209 - val_loss: 0.4619 - val_tp: 37.0000 - val_fn: 7.0000 - val_accuracy: 0.7902 - val_auc: 0.8603 - val_prc: 0.5251\n",
      "Epoch 54/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4532 - tp: 838.0000 - fn: 169.0000 - accuracy: 0.8024 - auc: 0.8672 - prc: 0.8273 - val_loss: 0.4578 - val_tp: 37.0000 - val_fn: 7.0000 - val_accuracy: 0.7951 - val_auc: 0.8618 - val_prc: 0.5266\n",
      "Epoch 55/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.4582 - tp: 830.0000 - fn: 177.0000 - accuracy: 0.8049 - auc: 0.8618 - prc: 0.8131 - val_loss: 0.4540 - val_tp: 37.0000 - val_fn: 7.0000 - val_accuracy: 0.8049 - val_auc: 0.8633 - val_prc: 0.5301\n",
      "Epoch 56/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4437 - tp: 847.0000 - fn: 160.0000 - accuracy: 0.8103 - auc: 0.8724 - prc: 0.8282 - val_loss: 0.4500 - val_tp: 37.0000 - val_fn: 7.0000 - val_accuracy: 0.8098 - val_auc: 0.8658 - val_prc: 0.5355\n",
      "Epoch 57/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4467 - tp: 845.0000 - fn: 162.0000 - accuracy: 0.8093 - auc: 0.8690 - prc: 0.8180 - val_loss: 0.4459 - val_tp: 37.0000 - val_fn: 7.0000 - val_accuracy: 0.8098 - val_auc: 0.8689 - val_prc: 0.5442\n",
      "Epoch 58/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4383 - tp: 844.0000 - fn: 163.0000 - accuracy: 0.8133 - auc: 0.8757 - prc: 0.8318 - val_loss: 0.4420 - val_tp: 38.0000 - val_fn: 6.0000 - val_accuracy: 0.8195 - val_auc: 0.8700 - val_prc: 0.5462\n",
      "Epoch 59/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4378 - tp: 848.0000 - fn: 159.0000 - accuracy: 0.8118 - auc: 0.8743 - prc: 0.8284 - val_loss: 0.4379 - val_tp: 38.0000 - val_fn: 6.0000 - val_accuracy: 0.8244 - val_auc: 0.8715 - val_prc: 0.5543\n",
      "Epoch 60/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4289 - tp: 846.0000 - fn: 161.0000 - accuracy: 0.8213 - auc: 0.8791 - prc: 0.8260 - val_loss: 0.4340 - val_tp: 39.0000 - val_fn: 5.0000 - val_accuracy: 0.8244 - val_auc: 0.8727 - val_prc: 0.5555\n",
      "Epoch 61/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 21ms/step - loss: 0.4222 - tp: 860.0000 - fn: 147.0000 - accuracy: 0.8237 - auc: 0.8840 - prc: 0.8437 - val_loss: 0.4303 - val_tp: 39.0000 - val_fn: 5.0000 - val_accuracy: 0.8244 - val_auc: 0.8742 - val_prc: 0.5592\n",
      "Epoch 62/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.4213 - tp: 866.0000 - fn: 141.0000 - accuracy: 0.8222 - auc: 0.8846 - prc: 0.8477 - val_loss: 0.4270 - val_tp: 39.0000 - val_fn: 5.0000 - val_accuracy: 0.8244 - val_auc: 0.8755 - val_prc: 0.5589\n",
      "Epoch 63/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4215 - tp: 860.0000 - fn: 147.0000 - accuracy: 0.8252 - auc: 0.8829 - prc: 0.8366 - val_loss: 0.4238 - val_tp: 39.0000 - val_fn: 5.0000 - val_accuracy: 0.8244 - val_auc: 0.8775 - val_prc: 0.5634\n",
      "Epoch 64/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4120 - tp: 862.0000 - fn: 145.0000 - accuracy: 0.8203 - auc: 0.8901 - prc: 0.8522 - val_loss: 0.4206 - val_tp: 39.0000 - val_fn: 5.0000 - val_accuracy: 0.8293 - val_auc: 0.8797 - val_prc: 0.5679\n",
      "Epoch 65/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.4091 - tp: 871.0000 - fn: 136.0000 - accuracy: 0.8312 - auc: 0.8909 - prc: 0.8431 - val_loss: 0.4176 - val_tp: 39.0000 - val_fn: 5.0000 - val_accuracy: 0.8293 - val_auc: 0.8802 - val_prc: 0.5682\n",
      "Epoch 66/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.4134 - tp: 867.0000 - fn: 140.0000 - accuracy: 0.8262 - auc: 0.8866 - prc: 0.8334 - val_loss: 0.4147 - val_tp: 39.0000 - val_fn: 5.0000 - val_accuracy: 0.8293 - val_auc: 0.8816 - val_prc: 0.5718\n",
      "Epoch 67/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3975 - tp: 874.0000 - fn: 133.0000 - accuracy: 0.8381 - auc: 0.8970 - prc: 0.8589 - val_loss: 0.4122 - val_tp: 39.0000 - val_fn: 5.0000 - val_accuracy: 0.8244 - val_auc: 0.8833 - val_prc: 0.5815\n",
      "Epoch 68/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.4018 - tp: 886.0000 - fn: 121.0000 - accuracy: 0.8421 - auc: 0.8929 - prc: 0.8448 - val_loss: 0.4099 - val_tp: 39.0000 - val_fn: 5.0000 - val_accuracy: 0.8293 - val_auc: 0.8847 - val_prc: 0.5842\n",
      "Epoch 69/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3996 - tp: 880.0000 - fn: 127.0000 - accuracy: 0.8416 - auc: 0.8931 - prc: 0.8466 - val_loss: 0.4078 - val_tp: 39.0000 - val_fn: 5.0000 - val_accuracy: 0.8293 - val_auc: 0.8866 - val_prc: 0.5889\n",
      "Epoch 70/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3903 - tp: 874.0000 - fn: 133.0000 - accuracy: 0.8391 - auc: 0.8986 - prc: 0.8527 - val_loss: 0.4058 - val_tp: 39.0000 - val_fn: 5.0000 - val_accuracy: 0.8244 - val_auc: 0.8871 - val_prc: 0.5859\n",
      "Epoch 71/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3916 - tp: 885.0000 - fn: 122.0000 - accuracy: 0.8421 - auc: 0.8968 - prc: 0.8598 - val_loss: 0.4037 - val_tp: 39.0000 - val_fn: 5.0000 - val_accuracy: 0.8244 - val_auc: 0.8885 - val_prc: 0.5923\n",
      "Epoch 72/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3835 - tp: 892.0000 - fn: 115.0000 - accuracy: 0.8505 - auc: 0.9014 - prc: 0.8547 - val_loss: 0.4017 - val_tp: 39.0000 - val_fn: 5.0000 - val_accuracy: 0.8293 - val_auc: 0.8912 - val_prc: 0.6018\n",
      "Epoch 73/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3824 - tp: 894.0000 - fn: 113.0000 - accuracy: 0.8505 - auc: 0.9010 - prc: 0.8478 - val_loss: 0.3995 - val_tp: 39.0000 - val_fn: 5.0000 - val_accuracy: 0.8293 - val_auc: 0.8917 - val_prc: 0.6031\n",
      "Epoch 74/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3815 - tp: 894.0000 - fn: 113.0000 - accuracy: 0.8510 - auc: 0.9001 - prc: 0.8487 - val_loss: 0.3970 - val_tp: 39.0000 - val_fn: 5.0000 - val_accuracy: 0.8293 - val_auc: 0.8930 - val_prc: 0.6072\n",
      "Epoch 75/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3794 - tp: 895.0000 - fn: 112.0000 - accuracy: 0.8530 - auc: 0.9023 - prc: 0.8604 - val_loss: 0.3948 - val_tp: 39.0000 - val_fn: 5.0000 - val_accuracy: 0.8293 - val_auc: 0.8939 - val_prc: 0.6247\n",
      "Epoch 76/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3697 - tp: 900.0000 - fn: 107.0000 - accuracy: 0.8575 - auc: 0.9084 - prc: 0.8586 - val_loss: 0.3925 - val_tp: 39.0000 - val_fn: 5.0000 - val_accuracy: 0.8293 - val_auc: 0.8948 - val_prc: 0.6300\n",
      "Epoch 77/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3697 - tp: 898.0000 - fn: 109.0000 - accuracy: 0.8535 - auc: 0.9068 - prc: 0.8578 - val_loss: 0.3900 - val_tp: 39.0000 - val_fn: 5.0000 - val_accuracy: 0.8390 - val_auc: 0.8966 - val_prc: 0.6388\n",
      "Epoch 78/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3628 - tp: 901.0000 - fn: 106.0000 - accuracy: 0.8595 - auc: 0.9110 - prc: 0.8756 - val_loss: 0.3876 - val_tp: 39.0000 - val_fn: 5.0000 - val_accuracy: 0.8390 - val_auc: 0.8977 - val_prc: 0.6405\n",
      "Epoch 79/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3558 - tp: 911.0000 - fn: 96.0000 - accuracy: 0.8659 - auc: 0.9134 - prc: 0.8723 - val_loss: 0.3851 - val_tp: 39.0000 - val_fn: 5.0000 - val_accuracy: 0.8390 - val_auc: 0.8994 - val_prc: 0.6458\n",
      "Epoch 80/100\n",
      "1/1 [==============================] - ETA: 0s - loss: 0.3569 - tp: 920.0000 - fn: 87.0000 - accuracy: 0.8679 - auc: 0.9112 - prc: 0.864 - 0s 24ms/step - loss: 0.3569 - tp: 920.0000 - fn: 87.0000 - accuracy: 0.8679 - auc: 0.9112 - prc: 0.8648 - val_loss: 0.3824 - val_tp: 39.0000 - val_fn: 5.0000 - val_accuracy: 0.8390 - val_auc: 0.9001 - val_prc: 0.6498\n",
      "Epoch 81/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3553 - tp: 908.0000 - fn: 99.0000 - accuracy: 0.8595 - auc: 0.9137 - prc: 0.8771 - val_loss: 0.3798 - val_tp: 39.0000 - val_fn: 5.0000 - val_accuracy: 0.8390 - val_auc: 0.9002 - val_prc: 0.6499\n",
      "Epoch 82/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3516 - tp: 924.0000 - fn: 83.0000 - accuracy: 0.8714 - auc: 0.9153 - prc: 0.8770 - val_loss: 0.3767 - val_tp: 39.0000 - val_fn: 5.0000 - val_accuracy: 0.8390 - val_auc: 0.9008 - val_prc: 0.6529\n",
      "Epoch 83/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3484 - tp: 915.0000 - fn: 92.0000 - accuracy: 0.8635 - auc: 0.9170 - prc: 0.8856 - val_loss: 0.3737 - val_tp: 39.0000 - val_fn: 5.0000 - val_accuracy: 0.8390 - val_auc: 0.9026 - val_prc: 0.6556\n",
      "Epoch 84/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3416 - tp: 911.0000 - fn: 96.0000 - accuracy: 0.8644 - auc: 0.9200 - prc: 0.8839 - val_loss: 0.3714 - val_tp: 39.0000 - val_fn: 5.0000 - val_accuracy: 0.8439 - val_auc: 0.9023 - val_prc: 0.6539\n",
      "Epoch 85/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3429 - tp: 916.0000 - fn: 91.0000 - accuracy: 0.8659 - auc: 0.9201 - prc: 0.8770 - val_loss: 0.3691 - val_tp: 39.0000 - val_fn: 5.0000 - val_accuracy: 0.8439 - val_auc: 0.9026 - val_prc: 0.6514\n",
      "Epoch 86/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3399 - tp: 923.0000 - fn: 84.0000 - accuracy: 0.8714 - auc: 0.9187 - prc: 0.8765 - val_loss: 0.3667 - val_tp: 39.0000 - val_fn: 5.0000 - val_accuracy: 0.8439 - val_auc: 0.9045 - val_prc: 0.6639\n",
      "Epoch 87/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3426 - tp: 916.0000 - fn: 91.0000 - accuracy: 0.8664 - auc: 0.9190 - prc: 0.8861 - val_loss: 0.3643 - val_tp: 39.0000 - val_fn: 5.0000 - val_accuracy: 0.8488 - val_auc: 0.9047 - val_prc: 0.6643\n",
      "Epoch 88/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3394 - tp: 929.0000 - fn: 78.0000 - accuracy: 0.8759 - auc: 0.9186 - prc: 0.8823 - val_loss: 0.3620 - val_tp: 39.0000 - val_fn: 5.0000 - val_accuracy: 0.8537 - val_auc: 0.9054 - val_prc: 0.6649\n",
      "Epoch 89/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3431 - tp: 919.0000 - fn: 88.0000 - accuracy: 0.8714 - auc: 0.9174 - prc: 0.8732 - val_loss: 0.3597 - val_tp: 39.0000 - val_fn: 5.0000 - val_accuracy: 0.8488 - val_auc: 0.9065 - val_prc: 0.6736\n",
      "Epoch 90/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3295 - tp: 925.0000 - fn: 82.0000 - accuracy: 0.8774 - auc: 0.9248 - prc: 0.8994 - val_loss: 0.3575 - val_tp: 39.0000 - val_fn: 5.0000 - val_accuracy: 0.8488 - val_auc: 0.9068 - val_prc: 0.6758\n",
      "Epoch 91/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3296 - tp: 923.0000 - fn: 84.0000 - accuracy: 0.8744 - auc: 0.9244 - prc: 0.8953 - val_loss: 0.3558 - val_tp: 39.0000 - val_fn: 5.0000 - val_accuracy: 0.8488 - val_auc: 0.9069 - val_prc: 0.6755\n",
      "Epoch 92/100\n",
      "1/1 [==============================] - 0s 28ms/step - loss: 0.3210 - tp: 927.0000 - fn: 80.0000 - accuracy: 0.8759 - auc: 0.9281 - prc: 0.9017 - val_loss: 0.3543 - val_tp: 39.0000 - val_fn: 5.0000 - val_accuracy: 0.8488 - val_auc: 0.9096 - val_prc: 0.6898\n",
      "Epoch 93/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3239 - tp: 921.0000 - fn: 86.0000 - accuracy: 0.8759 - auc: 0.9262 - prc: 0.8958 - val_loss: 0.3530 - val_tp: 39.0000 - val_fn: 5.0000 - val_accuracy: 0.8488 - val_auc: 0.9101 - val_prc: 0.6929\n",
      "Epoch 94/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3268 - tp: 928.0000 - fn: 79.0000 - accuracy: 0.8774 - auc: 0.9233 - prc: 0.8824 - val_loss: 0.3517 - val_tp: 39.0000 - val_fn: 5.0000 - val_accuracy: 0.8488 - val_auc: 0.9094 - val_prc: 0.6853\n",
      "Epoch 95/100\n",
      "1/1 [==============================] - 0s 24ms/step - loss: 0.3248 - tp: 928.0000 - fn: 79.0000 - accuracy: 0.8769 - auc: 0.9236 - prc: 0.8898 - val_loss: 0.3501 - val_tp: 39.0000 - val_fn: 5.0000 - val_accuracy: 0.8585 - val_auc: 0.9105 - val_prc: 0.6964\n",
      "Epoch 96/100\n",
      "1/1 [==============================] - 0s 25ms/step - loss: 0.3193 - tp: 930.0000 - fn: 77.0000 - accuracy: 0.8813 - auc: 0.9257 - prc: 0.8913 - val_loss: 0.3483 - val_tp: 39.0000 - val_fn: 5.0000 - val_accuracy: 0.8585 - val_auc: 0.9116 - val_prc: 0.7040\n",
      "Epoch 97/100\n",
      "1/1 [==============================] - 0s 23ms/step - loss: 0.3170 - tp: 928.0000 - fn: 79.0000 - accuracy: 0.8793 - auc: 0.9275 - prc: 0.8942 - val_loss: 0.3464 - val_tp: 39.0000 - val_fn: 5.0000 - val_accuracy: 0.8585 - val_auc: 0.9135 - val_prc: 0.7097\n",
      "Epoch 98/100\n",
      "1/1 [==============================] - 0s 22ms/step - loss: 0.3167 - tp: 933.0000 - fn: 74.0000 - accuracy: 0.8793 - auc: 0.9305 - prc: 0.8916 - val_loss: 0.3444 - val_tp: 39.0000 - val_fn: 5.0000 - val_accuracy: 0.8585 - val_auc: 0.9137 - val_prc: 0.7070\n",
      "Epoch 99/100\n",
      "1/1 [==============================] - 0s 27ms/step - loss: 0.3168 - tp: 930.0000 - fn: 77.0000 - accuracy: 0.8808 - auc: 0.9268 - prc: 0.8911 - val_loss: 0.3421 - val_tp: 39.0000 - val_fn: 5.0000 - val_accuracy: 0.8585 - val_auc: 0.9145 - val_prc: 0.7073\n",
      "Epoch 100/100\n",
      "1/1 [==============================] - 0s 21ms/step - loss: 0.3124 - tp: 930.0000 - fn: 77.0000 - accuracy: 0.8813 - auc: 0.9292 - prc: 0.8948 - val_loss: 0.3400 - val_tp: 39.0000 - val_fn: 5.0000 - val_accuracy: 0.8585 - val_auc: 0.9142 - val_prc: 0.7042\n"
     ]
    }
   ],
   "source": [
    "weighted_model = make_model()\n",
    "#weighted_model.load_weights(initial_weights)\n",
    "\n",
    "weighted_history = weighted_model.fit(\n",
    "    train_features,\n",
    "    train_labels,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    #callbacks=[early_stopping],\n",
    "    validation_data=(val_features, val_labels),\n",
    "    # The class weights go here\n",
    "    #class_weight=class_weight\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_predictions_weighted = weighted_model.predict(train_features, batch_size=BATCH_SIZE)\n",
    "test_predictions_weighted = weighted_model.predict(test_features, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bradycardia Detected (True Negatives):  166\n",
      "Bradycardia Incorrectly Detected (False Positives):  36\n",
      "False Alarm on detection (False Negatives):  2\n",
      "Not Bradycardia detected (True Positives):  52\n",
      "Total No Disease Diagnosis:  54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.82      0.90       202\n",
      "           1       0.59      0.96      0.73        54\n",
      "\n",
      "    accuracy                           0.85       256\n",
      "   macro avg       0.79      0.89      0.81       256\n",
      "weighted avg       0.90      0.85      0.86       256\n",
      "\n",
      "0.8923725705903924\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "weighted_results = weighted_model.evaluate(test_features, test_labels,\n",
    "                                           batch_size=BATCH_SIZE, verbose=0)\n",
    "# for name, value in zip(weighted_model.metrics_names, weighted_results):\n",
    "#   print(name, ': ', value)\n",
    "# print()\n",
    "\n",
    "plot_cm(test_labels, test_predictions_weighted)\n",
    "print(classification_report(test_labels, test_predictions_weighted>0.5))\n",
    "print(roc_auc_score(test_labels, test_predictions_weighted>0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "weighted_model.save_weights('./best_weights/weighted1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "30/63 [=============>................] - ETA: 0s - loss: 0.3341 - tp: 469.0000 - fn: 47.0000 - accuracy: 0.8652 - auc: 0.9242 - prc: 0.8621WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 1s 11ms/step - loss: 0.3178 - tp: 970.0000 - fn: 81.0000 - accuracy: 0.8770 - auc: 0.9295 - prc: 0.8867 - val_loss: 0.3089 - val_tp: 42.0000 - val_fn: 2.0000 - val_accuracy: 0.8780 - val_auc: 0.9351 - val_prc: 0.7708\n",
      "Epoch 2/50\n",
      "41/63 [==================>...........] - ETA: 0s - loss: 0.2686 - tp: 606.0000 - fn: 42.0000 - accuracy: 0.9009 - auc: 0.9471 - prc: 0.9223  WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2834 - tp: 942.0000 - fn: 65.0000 - accuracy: 0.8947 - auc: 0.9389 - prc: 0.9112 - val_loss: 0.3074 - val_tp: 39.0000 - val_fn: 5.0000 - val_accuracy: 0.8732 - val_auc: 0.9317 - val_prc: 0.7600\n",
      "Epoch 3/50\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.2656 - tp: 762.0000 - fn: 41.0000 - accuracy: 0.9050 - auc: 0.9458 - prc: 0.9256  WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2589 - tp: 959.0000 - fn: 48.0000 - accuracy: 0.9067 - auc: 0.9481 - prc: 0.9281 - val_loss: 0.3169 - val_tp: 39.0000 - val_fn: 5.0000 - val_accuracy: 0.8927 - val_auc: 0.9383 - val_prc: 0.7764\n",
      "Epoch 4/50\n",
      "41/63 [==================>...........] - ETA: 0s - loss: 0.5551 - tp: 14.0000 - fn: 0.0000e+00 - accuracy: 0.8438 - auc: 0.8254 - prc: 0.724 - ETA: 0s - loss: 0.2487 - tp: 634.0000 - fn: 29.0000 - accuracy: 0.9131 - auc: 0.9473 - prc: 0.9188  WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2385 - tp: 967.0000 - fn: 40.0000 - accuracy: 0.9191 - auc: 0.9519 - prc: 0.9272 - val_loss: 0.2527 - val_tp: 39.0000 - val_fn: 5.0000 - val_accuracy: 0.9073 - val_auc: 0.9497 - val_prc: 0.8172\n",
      "Epoch 5/50\n",
      "44/63 [===================>..........] - ETA: 0s - loss: 0.2267 - tp: 662.0000 - fn: 31.0000 - accuracy: 0.9219 - auc: 0.9570 - prc: 0.9384WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2294 - tp: 964.0000 - fn: 43.0000 - accuracy: 0.9206 - auc: 0.9552 - prc: 0.9363 - val_loss: 0.2406 - val_tp: 42.0000 - val_fn: 2.0000 - val_accuracy: 0.9122 - val_auc: 0.9517 - val_prc: 0.8026\n",
      "Epoch 6/50\n",
      "42/63 [===================>..........] - ETA: 0s - loss: 0.2099 - tp: 652.0000 - fn: 17.0000 - accuracy: 0.9301 - auc: 0.9610 - prc: 0.9460WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2157 - tp: 972.0000 - fn: 35.0000 - accuracy: 0.9240 - auc: 0.9601 - prc: 0.9424 - val_loss: 0.2400 - val_tp: 40.0000 - val_fn: 4.0000 - val_accuracy: 0.9220 - val_auc: 0.9496 - val_prc: 0.8002\n",
      "Epoch 7/50\n",
      "47/63 [=====================>........] - ETA: 0s - loss: 0.2166 - tp: 742.0000 - fn: 23.0000 - accuracy: 0.9262 - auc: 0.9579 - prc: 0.9434  WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.2085 - tp: 979.0000 - fn: 28.0000 - accuracy: 0.9295 - auc: 0.9614 - prc: 0.9462 - val_loss: 0.1970 - val_tp: 42.0000 - val_fn: 2.0000 - val_accuracy: 0.9366 - val_auc: 0.9629 - val_prc: 0.8570\n",
      "Epoch 8/50\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1955 - tp: 858.0000 - fn: 18.0000 - accuracy: 0.9386 - auc: 0.9624 - prc: 0.9470  WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1974 - tp: 987.0000 - fn: 20.0000 - accuracy: 0.9384 - auc: 0.9616 - prc: 0.9466 - val_loss: 0.2402 - val_tp: 41.0000 - val_fn: 3.0000 - val_accuracy: 0.9220 - val_auc: 0.9575 - val_prc: 0.8244\n",
      "Epoch 9/50\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1920 - tp: 866.0000 - fn: 17.0000 - accuracy: 0.9398 - auc: 0.9640 - prc: 0.9517  WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1934 - tp: 988.0000 - fn: 19.0000 - accuracy: 0.9389 - auc: 0.9639 - prc: 0.9494 - val_loss: 0.2037 - val_tp: 42.0000 - val_fn: 2.0000 - val_accuracy: 0.9366 - val_auc: 0.9627 - val_prc: 0.8528\n",
      "Epoch 10/50\n",
      "43/63 [===================>..........] - ETA: 0s - loss: 0.1846 - tp: 689.0000 - fn: 10.0000 - accuracy: 0.9411 - auc: 0.9660 - prc: 0.9535  WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1788 - tp: 988.0000 - fn: 19.0000 - accuracy: 0.9429 - auc: 0.9690 - prc: 0.9570 - val_loss: 0.2262 - val_tp: 41.0000 - val_fn: 3.0000 - val_accuracy: 0.9220 - val_auc: 0.9590 - val_prc: 0.8321\n",
      "Epoch 11/50\n",
      "41/63 [==================>...........] - ETA: 0s - loss: 0.1695 - tp: 658.0000 - fn: 10.0000 - accuracy: 0.9451 - auc: 0.9719 - prc: 0.9634WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1823 - tp: 988.0000 - fn: 19.0000 - accuracy: 0.9404 - auc: 0.9676 - prc: 0.9546 - val_loss: 0.1630 - val_tp: 42.0000 - val_fn: 2.0000 - val_accuracy: 0.9366 - val_auc: 0.9704 - val_prc: 0.8869\n",
      "Epoch 12/50\n",
      "31/63 [=============>................] - ETA: 0s - loss: 0.1920 - tp: 490.0000 - fn: 7.0000 - accuracy: 0.9395 - auc: 0.9645 - prc: 0.9529   WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1720 - tp: 996.0000 - fn: 11.0000 - accuracy: 0.9464 - auc: 0.9709 - prc: 0.9604 - val_loss: 0.2016 - val_tp: 41.0000 - val_fn: 3.0000 - val_accuracy: 0.9317 - val_auc: 0.9654 - val_prc: 0.8506\n",
      "Epoch 13/50\n",
      "36/63 [================>.............] - ETA: 0s - loss: 0.1577 - tp: 570.0000 - fn: 9.0000 - accuracy: 0.9505 - auc: 0.9732 - prc: 0.9658   WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1700 - tp: 994.0000 - fn: 13.0000 - accuracy: 0.9454 - auc: 0.9706 - prc: 0.9610 - val_loss: 0.1784 - val_tp: 42.0000 - val_fn: 2.0000 - val_accuracy: 0.9366 - val_auc: 0.9708 - val_prc: 0.8834\n",
      "Epoch 14/50\n",
      "36/63 [================>.............] - ETA: 0s - loss: 0.1621 - tp: 588.0000 - fn: 4.0000 - accuracy: 0.9549 - auc: 0.9700 - prc: 0.9575   WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1663 - tp: 999.0000 - fn: 8.0000 - accuracy: 0.9503 - auc: 0.9707 - prc: 0.9594 - val_loss: 0.1625 - val_tp: 42.0000 - val_fn: 2.0000 - val_accuracy: 0.9415 - val_auc: 0.9688 - val_prc: 0.8671\n",
      "Epoch 15/50\n",
      "39/63 [=================>............] - ETA: 0s - loss: 0.1602 - tp: 615.0000 - fn: 8.0000 - accuracy: 0.9495 - auc: 0.9715 - prc: 0.9603   WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1664 - tp: 991.0000 - fn: 16.0000 - accuracy: 0.9449 - auc: 0.9711 - prc: 0.9609 - val_loss: 0.1642 - val_tp: 42.0000 - val_fn: 2.0000 - val_accuracy: 0.9415 - val_auc: 0.9704 - val_prc: 0.8766\n",
      "Epoch 16/50\n",
      "37/63 [================>.............] - ETA: 0s - loss: 0.1599 - tp: 573.0000 - fn: 6.0000 - accuracy: 0.9502 - auc: 0.9735 - prc: 0.9640   WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1566 - tp: 993.0000 - fn: 14.0000 - accuracy: 0.9494 - auc: 0.9748 - prc: 0.9678 - val_loss: 0.1674 - val_tp: 42.0000 - val_fn: 2.0000 - val_accuracy: 0.9415 - val_auc: 0.9692 - val_prc: 0.8676\n",
      "Epoch 17/50\n",
      "46/63 [====================>.........] - ETA: 0s - loss: 0.1576 - tp: 713.0000 - fn: 10.0000 - accuracy: 0.9450 - auc: 0.9754 - prc: 0.9680WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1561 - tp: 995.0000 - fn: 12.0000 - accuracy: 0.9489 - auc: 0.9744 - prc: 0.9671 - val_loss: 0.1616 - val_tp: 42.0000 - val_fn: 2.0000 - val_accuracy: 0.9415 - val_auc: 0.9730 - val_prc: 0.8911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50\n",
      "44/63 [===================>..........] - ETA: 0s - loss: 0.1600 - tp: 689.0000 - fn: 6.0000 - accuracy: 0.9496 - auc: 0.9735 - prc: 0.9617   WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1539 - tp: 998.0000 - fn: 9.0000 - accuracy: 0.9513 - auc: 0.9761 - prc: 0.9659 - val_loss: 0.1644 - val_tp: 42.0000 - val_fn: 2.0000 - val_accuracy: 0.9415 - val_auc: 0.9717 - val_prc: 0.8824\n",
      "Epoch 19/50\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.1483 - tp: 808.0000 - fn: 6.0000 - accuracy: 0.9522 - auc: 0.9775 - prc: 0.9694   WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1534 - tp: 997.0000 - fn: 10.0000 - accuracy: 0.9494 - auc: 0.9765 - prc: 0.9690 - val_loss: 0.1642 - val_tp: 41.0000 - val_fn: 3.0000 - val_accuracy: 0.9366 - val_auc: 0.9719 - val_prc: 0.8837\n",
      "Epoch 20/50\n",
      "53/63 [========================>.....] - ETA: 0s - loss: 0.1584 - tp: 848.0000 - fn: 10.0000 - accuracy: 0.9475 - auc: 0.9748 - prc: 0.9662  WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1528 - tp: 996.0000 - fn: 11.0000 - accuracy: 0.9503 - auc: 0.9763 - prc: 0.9672 - val_loss: 0.1642 - val_tp: 42.0000 - val_fn: 2.0000 - val_accuracy: 0.9415 - val_auc: 0.9718 - val_prc: 0.8833\n",
      "Epoch 21/50\n",
      "31/63 [=============>................] - ETA: 0s - loss: 0.1788 - tp: 481.0000 - fn: 11.0000 - accuracy: 0.9415 - auc: 0.9676 - prc: 0.9525  WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1777 - tp: 985.0000 - fn: 22.0000 - accuracy: 0.9419 - auc: 0.9689 - prc: 0.9559 - val_loss: 0.1796 - val_tp: 42.0000 - val_fn: 2.0000 - val_accuracy: 0.9415 - val_auc: 0.9704 - val_prc: 0.8740\n",
      "Epoch 22/50\n",
      "50/63 [======================>.......] - ETA: 0s - loss: 0.1912 - tp: 783.0000 - fn: 23.0000 - accuracy: 0.9400 - auc: 0.9663 - prc: 0.9491  WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1925 - tp: 979.0000 - fn: 28.0000 - accuracy: 0.9379 - auc: 0.9663 - prc: 0.9499 - val_loss: 0.1564 - val_tp: 43.0000 - val_fn: 1.0000 - val_accuracy: 0.9463 - val_auc: 0.9712 - val_prc: 0.8791\n",
      "Epoch 23/50\n",
      "39/63 [=================>............] - ETA: 0s - loss: 0.1768 - tp: 625.0000 - fn: 6.0000 - accuracy: 0.9439 - auc: 0.9678 - prc: 0.9552WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1770 - tp: 992.0000 - fn: 15.0000 - accuracy: 0.9454 - auc: 0.9680 - prc: 0.9532 - val_loss: 0.2047 - val_tp: 42.0000 - val_fn: 2.0000 - val_accuracy: 0.9366 - val_auc: 0.9708 - val_prc: 0.8774\n",
      "Epoch 24/50\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1750 - tp: 874.0000 - fn: 14.0000 - accuracy: 0.9466 - auc: 0.9665 - prc: 0.9536  WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1757 - tp: 993.0000 - fn: 14.0000 - accuracy: 0.9459 - auc: 0.9669 - prc: 0.9539 - val_loss: 0.1499 - val_tp: 42.0000 - val_fn: 2.0000 - val_accuracy: 0.9415 - val_auc: 0.9778 - val_prc: 0.9116\n",
      "Epoch 25/50\n",
      "47/63 [=====================>........] - ETA: 0s - loss: 0.1668 - tp: 743.0000 - fn: 10.0000 - accuracy: 0.9501 - auc: 0.9716 - prc: 0.9572  WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1678 - tp: 993.0000 - fn: 14.0000 - accuracy: 0.9484 - auc: 0.9718 - prc: 0.9591 - val_loss: 0.1921 - val_tp: 43.0000 - val_fn: 1.0000 - val_accuracy: 0.9317 - val_auc: 0.9729 - val_prc: 0.8864\n",
      "Epoch 26/50\n",
      "40/63 [==================>...........] - ETA: 0s - loss: 0.1779 - tp: 644.0000 - fn: 17.0000 - accuracy: 0.9367 - auc: 0.9680 - prc: 0.9579  WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1651 - tp: 986.0000 - fn: 21.0000 - accuracy: 0.9439 - auc: 0.9712 - prc: 0.9606 - val_loss: 0.1822 - val_tp: 42.0000 - val_fn: 2.0000 - val_accuracy: 0.9366 - val_auc: 0.9702 - val_prc: 0.8665\n",
      "Epoch 27/50\n",
      "40/63 [==================>...........] - ETA: 0s - loss: 0.1582 - tp: 620.0000 - fn: 7.0000 - accuracy: 0.9516 - auc: 0.9745 - prc: 0.9628   WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1572 - tp: 993.0000 - fn: 14.0000 - accuracy: 0.9499 - auc: 0.9746 - prc: 0.9658 - val_loss: 0.1546 - val_tp: 42.0000 - val_fn: 2.0000 - val_accuracy: 0.9415 - val_auc: 0.9742 - val_prc: 0.9045\n",
      "Epoch 28/50\n",
      "40/63 [==================>...........] - ETA: 0s - loss: 0.1576 - tp: 632.0000 - fn: 10.0000 - accuracy: 0.9484 - auc: 0.9737 - prc: 0.9660WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1556 - tp: 995.0000 - fn: 12.0000 - accuracy: 0.9503 - auc: 0.9740 - prc: 0.9653 - val_loss: 0.1242 - val_tp: 43.0000 - val_fn: 1.0000 - val_accuracy: 0.9463 - val_auc: 0.9799 - val_prc: 0.9217\n",
      "Epoch 29/50\n",
      "34/63 [===============>..............] - ETA: 0s - loss: 0.1611 - tp: 549.0000 - fn: 8.0000 - accuracy: 0.9485 - auc: 0.9717 - prc: 0.9646WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1573 - tp: 993.0000 - fn: 14.0000 - accuracy: 0.9499 - auc: 0.9745 - prc: 0.9662 - val_loss: 0.1285 - val_tp: 41.0000 - val_fn: 3.0000 - val_accuracy: 0.9415 - val_auc: 0.9771 - val_prc: 0.9071\n",
      "Epoch 30/50\n",
      "36/63 [================>.............] - ETA: 0s - loss: 0.1491 - tp: 585.0000 - fn: 6.0000 - accuracy: 0.9531 - auc: 0.9771 - prc: 0.9699   WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1518 - tp: 995.0000 - fn: 12.0000 - accuracy: 0.9508 - auc: 0.9766 - prc: 0.9684 - val_loss: 0.1519 - val_tp: 44.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9561 - val_auc: 0.9752 - val_prc: 0.8958\n",
      "Epoch 31/50\n",
      "37/63 [================>.............] - ETA: 0s - loss: 0.1596 - tp: 591.0000 - fn: 10.0000 - accuracy: 0.9502 - auc: 0.9753 - prc: 0.9670  WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1553 - tp: 992.0000 - fn: 15.0000 - accuracy: 0.9518 - auc: 0.9752 - prc: 0.9667 - val_loss: 0.1648 - val_tp: 44.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9512 - val_auc: 0.9752 - val_prc: 0.8983\n",
      "Epoch 32/50\n",
      "38/63 [=================>............] - ETA: 0s - loss: 0.1308 - tp: 588.0000 - fn: 4.0000 - accuracy: 0.9597 - auc: 0.9808 - prc: 0.9716   WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1431 - tp: 999.0000 - fn: 8.0000 - accuracy: 0.9538 - auc: 0.9786 - prc: 0.9722 - val_loss: 0.1431 - val_tp: 44.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9512 - val_auc: 0.9797 - val_prc: 0.9189\n",
      "Epoch 33/50\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1385 - tp: 861.0000 - fn: 4.0000 - accuracy: 0.9572 - auc: 0.9795 - prc: 0.9737   WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1417 - tp: 1003.0000 - fn: 4.0000 - accuracy: 0.9568 - auc: 0.9783 - prc: 0.9711 - val_loss: 0.1255 - val_tp: 43.0000 - val_fn: 1.0000 - val_accuracy: 0.9512 - val_auc: 0.9796 - val_prc: 0.9200\n",
      "Epoch 34/50\n",
      "37/63 [================>.............] - ETA: 0s - loss: 0.1447 - tp: 577.0000 - fn: 5.0000 - accuracy: 0.9544 - auc: 0.9764 - prc: 0.9698   WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1388 - tp: 1001.0000 - fn: 6.0000 - accuracy: 0.9573 - auc: 0.9782 - prc: 0.9724 - val_loss: 0.1446 - val_tp: 44.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9561 - val_auc: 0.9771 - val_prc: 0.9078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50\n",
      "42/63 [===================>..........] - ETA: 0s - loss: 0.1402 - tp: 667.0000 - fn: 6.0000 - accuracy: 0.9561 - auc: 0.9780 - prc: 0.9726WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1425 - tp: 999.0000 - fn: 8.0000 - accuracy: 0.9553 - auc: 0.9771 - prc: 0.9710 - val_loss: 0.1342 - val_tp: 43.0000 - val_fn: 1.0000 - val_accuracy: 0.9512 - val_auc: 0.9790 - val_prc: 0.9156\n",
      "Epoch 36/50\n",
      "47/63 [=====================>........] - ETA: 0s - loss: 0.1194 - tp: 743.0000 - fn: 4.0000 - accuracy: 0.9628 - auc: 0.9840 - prc: 0.9803   WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1344 - tp: 1002.0000 - fn: 5.0000 - accuracy: 0.9578 - auc: 0.9802 - prc: 0.9754 - val_loss: 0.1260 - val_tp: 44.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9561 - val_auc: 0.9804 - val_prc: 0.9232\n",
      "Epoch 37/50\n",
      "42/63 [===================>..........] - ETA: 0s - loss: 0.1347 - tp: 677.0000 - fn: 2.0000 - accuracy: 0.9606 - auc: 0.9785 - prc: 0.9723   WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1372 - tp: 1004.0000 - fn: 3.0000 - accuracy: 0.9578 - auc: 0.9792 - prc: 0.9732 - val_loss: 0.1273 - val_tp: 44.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9561 - val_auc: 0.9808 - val_prc: 0.9249\n",
      "Epoch 38/50\n",
      "41/63 [==================>...........] - ETA: 0s - loss: 0.1382 - tp: 669.0000 - fn: 4.0000 - accuracy: 0.9566 - auc: 0.9792 - prc: 0.9761WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1353 - tp: 1002.0000 - fn: 5.0000 - accuracy: 0.9583 - auc: 0.9796 - prc: 0.9738 - val_loss: 0.1332 - val_tp: 44.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9561 - val_auc: 0.9791 - val_prc: 0.9163\n",
      "Epoch 39/50\n",
      "43/63 [===================>..........] - ETA: 0s - loss: 0.1330 - tp: 690.0000 - fn: 2.0000 - accuracy: 0.9608 - auc: 0.9793 - prc: 0.9748   WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1324 - tp: 1005.0000 - fn: 2.0000 - accuracy: 0.9598 - auc: 0.9801 - prc: 0.9745 - val_loss: 0.1322 - val_tp: 44.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9561 - val_auc: 0.9798 - val_prc: 0.9198\n",
      "Epoch 40/50\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.1416 - tp: 825.0000 - fn: 2.0000 - accuracy: 0.9565 - auc: 0.9773 - prc: 0.9728WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1323 - tp: 1005.0000 - fn: 2.0000 - accuracy: 0.9598 - auc: 0.9804 - prc: 0.9759 - val_loss: 0.1330 - val_tp: 44.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9561 - val_auc: 0.9796 - val_prc: 0.9179\n",
      "Epoch 41/50\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.1513 - tp: 806.0000 - fn: 10.0000 - accuracy: 0.9516 - auc: 0.9754 - prc: 0.9688  WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1511 - tp: 994.0000 - fn: 13.0000 - accuracy: 0.9518 - auc: 0.9755 - prc: 0.9692 - val_loss: 0.1854 - val_tp: 44.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9512 - val_auc: 0.9727 - val_prc: 0.8816\n",
      "Epoch 42/50\n",
      "55/63 [=========================>....] - ETA: 0s - loss: 0.1540 - tp: 864.0000 - fn: 15.0000 - accuracy: 0.9489 - auc: 0.9768 - prc: 0.9703  WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1548 - tp: 992.0000 - fn: 15.0000 - accuracy: 0.9499 - auc: 0.9763 - prc: 0.9688 - val_loss: 0.1740 - val_tp: 42.0000 - val_fn: 2.0000 - val_accuracy: 0.9415 - val_auc: 0.9749 - val_prc: 0.8923\n",
      "Epoch 43/50\n",
      "45/63 [====================>.........] - ETA: 0s - loss: 0.1964 - tp: 700.0000 - fn: 24.0000 - accuracy: 0.9368 - auc: 0.9664 - prc: 0.9466  WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1938 - tp: 979.0000 - fn: 28.0000 - accuracy: 0.9394 - auc: 0.9663 - prc: 0.9488 - val_loss: 0.1443 - val_tp: 43.0000 - val_fn: 1.0000 - val_accuracy: 0.9463 - val_auc: 0.9800 - val_prc: 0.9257\n",
      "Epoch 44/50\n",
      "39/63 [=================>............] - ETA: 0s - loss: 0.1516 - tp: 631.0000 - fn: 10.0000 - accuracy: 0.9543 - auc: 0.9766 - prc: 0.9709  WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1636 - tp: 989.0000 - fn: 18.0000 - accuracy: 0.9494 - auc: 0.9738 - prc: 0.9657 - val_loss: 0.1710 - val_tp: 43.0000 - val_fn: 1.0000 - val_accuracy: 0.9463 - val_auc: 0.9760 - val_prc: 0.8968\n",
      "Epoch 45/50\n",
      "42/63 [===================>..........] - ETA: 0s - loss: 0.1526 - tp: 663.0000 - fn: 10.0000 - accuracy: 0.9516 - auc: 0.9751 - prc: 0.9676WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1577 - tp: 989.0000 - fn: 18.0000 - accuracy: 0.9484 - auc: 0.9750 - prc: 0.9682 - val_loss: 0.1730 - val_tp: 43.0000 - val_fn: 1.0000 - val_accuracy: 0.9463 - val_auc: 0.9766 - val_prc: 0.9073\n",
      "Epoch 46/50\n",
      "54/63 [========================>.....] - ETA: 0s - loss: 0.1528 - tp: 836.0000 - fn: 20.0000 - accuracy: 0.9468 - auc: 0.9762 - prc: 0.9671  WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1535 - tp: 987.0000 - fn: 20.0000 - accuracy: 0.9484 - auc: 0.9756 - prc: 0.9672 - val_loss: 0.1261 - val_tp: 44.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9512 - val_auc: 0.9828 - val_prc: 0.9362\n",
      "Epoch 47/50\n",
      "42/63 [===================>..........] - ETA: 0s - loss: 0.1568 - tp: 676.0000 - fn: 6.0000 - accuracy: 0.9531 - auc: 0.9738 - prc: 0.9640   WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1504 - tp: 1000.0000 - fn: 7.0000 - accuracy: 0.9558 - auc: 0.9754 - prc: 0.9665 - val_loss: 0.1299 - val_tp: 44.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9512 - val_auc: 0.9816 - val_prc: 0.9290\n",
      "Epoch 48/50\n",
      "38/63 [=================>............] - ETA: 0s - loss: 0.1352 - tp: 606.0000 - fn: 4.0000 - accuracy: 0.9556 - auc: 0.9804 - prc: 0.9763   WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1468 - tp: 992.0000 - fn: 15.0000 - accuracy: 0.9508 - auc: 0.9780 - prc: 0.9692 - val_loss: 0.2298 - val_tp: 44.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9512 - val_auc: 0.9682 - val_prc: 0.8436\n",
      "Epoch 49/50\n",
      "41/63 [==================>...........] - ETA: 0s - loss: 0.1313 - tp: 657.0000 - fn: 4.0000 - accuracy: 0.9627 - auc: 0.9802 - prc: 0.9725   WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1407 - tp: 1000.0000 - fn: 7.0000 - accuracy: 0.9558 - auc: 0.9793 - prc: 0.9729 - val_loss: 0.1245 - val_tp: 44.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9561 - val_auc: 0.9819 - val_prc: 0.9292\n",
      "Epoch 50/50\n",
      "51/63 [=======================>......] - ETA: 0s - loss: 0.1363 - tp: 805.0000 - fn: 5.0000 - accuracy: 0.9559 - auc: 0.9793 - prc: 0.9743WARNING:tensorflow:Can save best model only with val_acc available, skipping.\n",
      "63/63 [==============================] - 0s 2ms/step - loss: 0.1351 - tp: 1001.0000 - fn: 6.0000 - accuracy: 0.9568 - auc: 0.9798 - prc: 0.9749 - val_loss: 0.1416 - val_tp: 44.0000 - val_fn: 0.0000e+00 - val_accuracy: 0.9561 - val_auc: 0.9798 - val_prc: 0.9211\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x199301593d0>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import snapshot.SnapshotCallbackBuilder\n",
    "\n",
    "M = 10 # number of snapshots\n",
    "nb_epoch = T = 200 # number of epochs\n",
    "alpha_zero = 0.0022 # initial learning rate\n",
    "model_prefix = 'Model_'\n",
    "\n",
    "snapshot = ecg_utility.snapshot.SnapshotCallbackBuilder(T, M, alpha_zero) \n",
    "# model = weighted_model\n",
    "model = make_model() # Some model that has been compiled\n",
    "# #model.load_weights(initial_weights)\n",
    "model.load_weights('./best_weights/weighted1')\n",
    "\n",
    "model.fit(train_features, train_labels, \n",
    "          epochs = 50,\n",
    "          callbacks=snapshot.get_callbacks(model_prefix=model_prefix),\n",
    "          validation_data=(val_features, val_labels), \n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bradycardia Detected (True Negatives):  184\n",
      "Bradycardia Incorrectly Detected (False Positives):  18\n",
      "False Alarm on detection (False Negatives):  0\n",
      "Not Bradycardia detected (True Positives):  54\n",
      "Total No Disease Diagnosis:  54\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95       202\n",
      "           1       0.75      1.00      0.86        54\n",
      "\n",
      "    accuracy                           0.93       256\n",
      "   macro avg       0.88      0.96      0.91       256\n",
      "weighted avg       0.95      0.93      0.93       256\n",
      "\n",
      "0.9554455445544555\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#results_snap = model.evaluate(test_features, test_labels,batch_size=BATCH_SIZE, verbose=0)\n",
    "# for name, value in zip(weighted_model.metrics_names, weighted_results):\n",
    "#   print(name, ': ', value)\n",
    "# print()\n",
    "\n",
    "results_snap = model.predict(test_features, batch_size = BATCH_SIZE)\n",
    "\n",
    "plot_cm(test_labels, results_snap)\n",
    "print(classification_report(test_labels, results_snap>0.5))\n",
    "print(roc_auc_score(test_labels, results_snap>0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.save_weights('./best_weights/check1')\n",
    "# model.save_weights('./best_weights/check2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method fit in module tensorflow.python.keras.engine.training:\n",
      "\n",
      "fit(x=None, y=None, batch_size=None, epochs=1, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_batch_size=None, validation_freq=1, max_queue_size=10, workers=1, use_multiprocessing=False) method of tensorflow.python.keras.engine.sequential.Sequential instance\n",
      "    Trains the model for a fixed number of epochs (iterations on a dataset).\n",
      "    \n",
      "    Arguments:\n",
      "        x: Input data. It could be:\n",
      "          - A Numpy array (or array-like), or a list of arrays\n",
      "            (in case the model has multiple inputs).\n",
      "          - A TensorFlow tensor, or a list of tensors\n",
      "            (in case the model has multiple inputs).\n",
      "          - A dict mapping input names to the corresponding array/tensors,\n",
      "            if the model has named inputs.\n",
      "          - A `tf.data` dataset. Should return a tuple\n",
      "            of either `(inputs, targets)` or\n",
      "            `(inputs, targets, sample_weights)`.\n",
      "          - A generator or `keras.utils.Sequence` returning `(inputs, targets)`\n",
      "            or `(inputs, targets, sample_weights)`.\n",
      "          A more detailed description of unpacking behavior for iterator types\n",
      "          (Dataset, generator, Sequence) is given below.\n",
      "        y: Target data. Like the input data `x`,\n",
      "          it could be either Numpy array(s) or TensorFlow tensor(s).\n",
      "          It should be consistent with `x` (you cannot have Numpy inputs and\n",
      "          tensor targets, or inversely). If `x` is a dataset, generator,\n",
      "          or `keras.utils.Sequence` instance, `y` should\n",
      "          not be specified (since targets will be obtained from `x`).\n",
      "        batch_size: Integer or `None`.\n",
      "            Number of samples per gradient update.\n",
      "            If unspecified, `batch_size` will default to 32.\n",
      "            Do not specify the `batch_size` if your data is in the\n",
      "            form of datasets, generators, or `keras.utils.Sequence` instances\n",
      "            (since they generate batches).\n",
      "        epochs: Integer. Number of epochs to train the model.\n",
      "            An epoch is an iteration over the entire `x` and `y`\n",
      "            data provided.\n",
      "            Note that in conjunction with `initial_epoch`,\n",
      "            `epochs` is to be understood as \"final epoch\".\n",
      "            The model is not trained for a number of iterations\n",
      "            given by `epochs`, but merely until the epoch\n",
      "            of index `epochs` is reached.\n",
      "        verbose: 0, 1, or 2. Verbosity mode.\n",
      "            0 = silent, 1 = progress bar, 2 = one line per epoch.\n",
      "            Note that the progress bar is not particularly useful when\n",
      "            logged to a file, so verbose=2 is recommended when not running\n",
      "            interactively (eg, in a production environment).\n",
      "        callbacks: List of `keras.callbacks.Callback` instances.\n",
      "            List of callbacks to apply during training.\n",
      "            See `tf.keras.callbacks`.\n",
      "        validation_split: Float between 0 and 1.\n",
      "            Fraction of the training data to be used as validation data.\n",
      "            The model will set apart this fraction of the training data,\n",
      "            will not train on it, and will evaluate\n",
      "            the loss and any model metrics\n",
      "            on this data at the end of each epoch.\n",
      "            The validation data is selected from the last samples\n",
      "            in the `x` and `y` data provided, before shuffling. This argument is\n",
      "            not supported when `x` is a dataset, generator or\n",
      "           `keras.utils.Sequence` instance.\n",
      "        validation_data: Data on which to evaluate\n",
      "            the loss and any model metrics at the end of each epoch.\n",
      "            The model will not be trained on this data. Thus, note the fact\n",
      "            that the validation loss of data provided using `validation_split`\n",
      "            or `validation_data` is not affected by regularization layers like\n",
      "            noise and dropuout.\n",
      "            `validation_data` will override `validation_split`.\n",
      "            `validation_data` could be:\n",
      "              - tuple `(x_val, y_val)` of Numpy arrays or tensors\n",
      "              - tuple `(x_val, y_val, val_sample_weights)` of Numpy arrays\n",
      "              - dataset\n",
      "            For the first two cases, `batch_size` must be provided.\n",
      "            For the last case, `validation_steps` could be provided.\n",
      "            Note that `validation_data` does not support all the data types that\n",
      "            are supported in `x`, eg, dict, generator or `keras.utils.Sequence`.\n",
      "        shuffle: Boolean (whether to shuffle the training data\n",
      "            before each epoch) or str (for 'batch'). This argument is ignored\n",
      "            when `x` is a generator. 'batch' is a special option for dealing\n",
      "            with the limitations of HDF5 data; it shuffles in batch-sized\n",
      "            chunks. Has no effect when `steps_per_epoch` is not `None`.\n",
      "        class_weight: Optional dictionary mapping class indices (integers)\n",
      "            to a weight (float) value, used for weighting the loss function\n",
      "            (during training only).\n",
      "            This can be useful to tell the model to\n",
      "            \"pay more attention\" to samples from\n",
      "            an under-represented class.\n",
      "        sample_weight: Optional Numpy array of weights for\n",
      "            the training samples, used for weighting the loss function\n",
      "            (during training only). You can either pass a flat (1D)\n",
      "            Numpy array with the same length as the input samples\n",
      "            (1:1 mapping between weights and samples),\n",
      "            or in the case of temporal data,\n",
      "            you can pass a 2D array with shape\n",
      "            `(samples, sequence_length)`,\n",
      "            to apply a different weight to every timestep of every sample. This\n",
      "            argument is not supported when `x` is a dataset, generator, or\n",
      "           `keras.utils.Sequence` instance, instead provide the sample_weights\n",
      "            as the third element of `x`.\n",
      "        initial_epoch: Integer.\n",
      "            Epoch at which to start training\n",
      "            (useful for resuming a previous training run).\n",
      "        steps_per_epoch: Integer or `None`.\n",
      "            Total number of steps (batches of samples)\n",
      "            before declaring one epoch finished and starting the\n",
      "            next epoch. When training with input tensors such as\n",
      "            TensorFlow data tensors, the default `None` is equal to\n",
      "            the number of samples in your dataset divided by\n",
      "            the batch size, or 1 if that cannot be determined. If x is a\n",
      "            `tf.data` dataset, and 'steps_per_epoch'\n",
      "            is None, the epoch will run until the input dataset is exhausted.\n",
      "            When passing an infinitely repeating dataset, you must specify the\n",
      "            `steps_per_epoch` argument. This argument is not supported with\n",
      "            array inputs.\n",
      "        validation_steps: Only relevant if `validation_data` is provided and\n",
      "            is a `tf.data` dataset. Total number of steps (batches of\n",
      "            samples) to draw before stopping when performing validation\n",
      "            at the end of every epoch. If 'validation_steps' is None, validation\n",
      "            will run until the `validation_data` dataset is exhausted. In the\n",
      "            case of an infinitely repeated dataset, it will run into an\n",
      "            infinite loop. If 'validation_steps' is specified and only part of\n",
      "            the dataset will be consumed, the evaluation will start from the\n",
      "            beginning of the dataset at each epoch. This ensures that the same\n",
      "            validation samples are used every time.\n",
      "        validation_batch_size: Integer or `None`.\n",
      "            Number of samples per validation batch.\n",
      "            If unspecified, will default to `batch_size`.\n",
      "            Do not specify the `validation_batch_size` if your data is in the\n",
      "            form of datasets, generators, or `keras.utils.Sequence` instances\n",
      "            (since they generate batches).\n",
      "        validation_freq: Only relevant if validation data is provided. Integer\n",
      "            or `collections_abc.Container` instance (e.g. list, tuple, etc.).\n",
      "            If an integer, specifies how many training epochs to run before a\n",
      "            new validation run is performed, e.g. `validation_freq=2` runs\n",
      "            validation every 2 epochs. If a Container, specifies the epochs on\n",
      "            which to run validation, e.g. `validation_freq=[1, 2, 10]` runs\n",
      "            validation at the end of the 1st, 2nd, and 10th epochs.\n",
      "        max_queue_size: Integer. Used for generator or `keras.utils.Sequence`\n",
      "            input only. Maximum size for the generator queue.\n",
      "            If unspecified, `max_queue_size` will default to 10.\n",
      "        workers: Integer. Used for generator or `keras.utils.Sequence` input\n",
      "            only. Maximum number of processes to spin up\n",
      "            when using process-based threading. If unspecified, `workers`\n",
      "            will default to 1. If 0, will execute the generator on the main\n",
      "            thread.\n",
      "        use_multiprocessing: Boolean. Used for generator or\n",
      "            `keras.utils.Sequence` input only. If `True`, use process-based\n",
      "            threading. If unspecified, `use_multiprocessing` will default to\n",
      "            `False`. Note that because this implementation relies on\n",
      "            multiprocessing, you should not pass non-picklable arguments to\n",
      "            the generator as they can't be passed easily to children processes.\n",
      "    \n",
      "    Unpacking behavior for iterator-like inputs:\n",
      "        A common pattern is to pass a tf.data.Dataset, generator, or\n",
      "      tf.keras.utils.Sequence to the `x` argument of fit, which will in fact\n",
      "      yield not only features (x) but optionally targets (y) and sample weights.\n",
      "      Keras requires that the output of such iterator-likes be unambiguous. The\n",
      "      iterator should return a tuple of length 1, 2, or 3, where the optional\n",
      "      second and third elements will be used for y and sample_weight\n",
      "      respectively. Any other type provided will be wrapped in a length one\n",
      "      tuple, effectively treating everything as 'x'. When yielding dicts, they\n",
      "      should still adhere to the top-level tuple structure.\n",
      "      e.g. `({\"x0\": x0, \"x1\": x1}, y)`. Keras will not attempt to separate\n",
      "      features, targets, and weights from the keys of a single dict.\n",
      "        A notable unsupported data type is the namedtuple. The reason is that\n",
      "      it behaves like both an ordered datatype (tuple) and a mapping\n",
      "      datatype (dict). So given a namedtuple of the form:\n",
      "          `namedtuple(\"example_tuple\", [\"y\", \"x\"])`\n",
      "      it is ambiguous whether to reverse the order of the elements when\n",
      "      interpreting the value. Even worse is a tuple of the form:\n",
      "          `namedtuple(\"other_tuple\", [\"x\", \"y\", \"z\"])`\n",
      "      where it is unclear if the tuple was intended to be unpacked into x, y,\n",
      "      and sample_weight or passed through as a single element to `x`. As a\n",
      "      result the data processing code will simply raise a ValueError if it\n",
      "      encounters a namedtuple. (Along with instructions to remedy the issue.)\n",
      "    \n",
      "    Returns:\n",
      "        A `History` object. Its `History.history` attribute is\n",
      "        a record of training loss values and metrics values\n",
      "        at successive epochs, as well as validation loss values\n",
      "        and validation metrics values (if applicable).\n",
      "    \n",
      "    Raises:\n",
      "        RuntimeError: 1. If the model was never compiled or,\n",
      "        2. If `model.fit` is  wrapped in `tf.function`.\n",
      "    \n",
      "        ValueError: In case of mismatch between the provided input data\n",
      "            and what the model expects.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(model.fit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
